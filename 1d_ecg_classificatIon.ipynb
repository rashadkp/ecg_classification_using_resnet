{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jyIMzGSA-_oZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import wfdb\n",
    "import pandas as pd\n",
    "import sys\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "A43FYGHX_iX-"
   },
   "outputs": [],
   "source": [
    "#defenition of data path and excel file path\n",
    "path = '/home/abhishek/rashad_internship/Physionet/ptb-xl-1.0.3/'\n",
    "excel = '/home/abhishek/rashad_internship/Physionet/ptb-xl-1.0.3/ptbxl_database.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tozT3NrF_kAl"
   },
   "outputs": [],
   "source": [
    "#custom class definition\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import wfdb\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "class Custom_class(Dataset):\n",
    "    def __init__(self, excelfile, path, num_data, transform=None, data_split='train'):\n",
    "        self.dat = pd.read_csv(excelfile)\n",
    "        self.col = self.dat['filename_hr']  # only 500 hz files are used for training\n",
    "        self.label = self.dat['scp_codes']  # used for labeling\n",
    "        self.strat_fold = self.dat['strat_fold']  # Load strat_fold column\n",
    "        self.path = path\n",
    "        self.transform = transform  # Initialize the transform attribute\n",
    "        self.num_data = num_data\n",
    "        self.data_split = data_split\n",
    "\n",
    "        if self.data_split == 'train':\n",
    "            self.indices = [idx for idx in range(self.num_data) if (self.strat_fold[idx] != 9 and self.strat_fold[idx] != 10)]\n",
    "        elif self.data_split == 'test':\n",
    "            self.indices = [idx for idx in range(self.num_data) if (self.strat_fold[idx] == 9 )]\n",
    "        elif self.data_split == 'val':\n",
    "            self.indices = [idx for idx in range(self.num_data) if (self.strat_fold[idx] == 10 )]\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = self.indices[idx]  # Adjust index to match filtered data\n",
    "        y, _ = wfdb.rdsamp(self.path + self.col[idx])  # Use channel 0\n",
    "        y = y.astype(np.float32)\n",
    "        y = np.transpose(y)\n",
    "\n",
    "        # Apply filtering\n",
    "        y = self.bandpass_filter(y, 1, 47, 500)  # applying BPF\n",
    "\n",
    "        # Normalize using z-score\n",
    "        y = self.z_score_normalize(y)\n",
    "        y = y.astype(np.float32)\n",
    "\n",
    "        scp_code_dict = ast.literal_eval(self.label[idx])  # Fetching label from the scp_codes column\n",
    "\n",
    "        # Check if the first key is 'NORM' and assign the label accordingly\n",
    "        first_key = max(scp_code_dict, key=scp_code_dict.get)  # one key in scp_code dictionary with highest value is considered as label\n",
    "        label = 0 if first_key == 'NORM' else 1  # if label is NORM then encoded as 1 else 0\n",
    "\n",
    "        if self.transform:\n",
    "            y = self.transform(y)\n",
    "\n",
    "        return y[0, :, :], label\n",
    "\n",
    "    def bandpass_filter(self, data, lowcut, highcut, fs, order=3):\n",
    "        nyquist = 0.5 * fs\n",
    "        low = lowcut / nyquist\n",
    "        high = highcut / nyquist\n",
    "        b, a = butter(order, [low, high], btype='band')\n",
    "        y = filtfilt(b, a, data, axis=1)\n",
    "        return y\n",
    "\n",
    "    def z_score_normalize(self, data):\n",
    "        mean = np.mean(data, axis=1, keepdims=True)\n",
    "        std = np.std(data, axis=1, keepdims=True)\n",
    "        normalized_data = (data - mean) / std\n",
    "        return normalized_data\n",
    "\n",
    "# Example usage\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# For training data, TOTAL 7000 data is used for TRAINING AND TESTING\n",
    "train_dataset = Custom_class(excel, path, num_data=7000, transform=transform, data_split='train')\n",
    "\n",
    "# For test data\n",
    "test_dataset = Custom_class(excel, path, num_data=7000, transform=transform, data_split='test')\n",
    "\n",
    "# For validation data\n",
    "val_dataset = Custom_class(excel, path, num_data=7000, transform=transform, data_split='val')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5359\n",
      "812\n",
      "829\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XI7KUi3h_-iL"
   },
   "outputs": [],
   "source": [
    "#MODEL DEFINITION\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the Res_Block_1\n",
    "class ResBlock1(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResBlock1, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=2, stride=2, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv3 = nn.Conv1d(out_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm1d(out_channels)\n",
    "        self.adjust_channels = nn.Conv1d(in_channels, out_channels, kernel_size=2, stride=2, padding=1)\n",
    "        self.adjust_bn = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.adjust_channels(x)\n",
    "        shortcut = self.adjust_bn(shortcut)\n",
    "\n",
    "        x = F.leaky_relu(self.bn1(self.conv1(x)))\n",
    "        x = F.leaky_relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = x + shortcut\n",
    "        x = F.leaky_relu(x)\n",
    "        return x\n",
    "\n",
    "# Define the Res_Block_2\n",
    "class ResBlock2(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResBlock2, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv3 = nn.Conv1d(out_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm1d(out_channels)\n",
    "        self.adjust_channels = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.adjust_bn = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.adjust_channels(x)\n",
    "        shortcut = self.adjust_bn(shortcut)\n",
    "\n",
    "        x = F.leaky_relu(self.bn1(self.conv1(x)))\n",
    "        x = F.leaky_relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = x + shortcut\n",
    "        x = F.leaky_relu(x)\n",
    "        return x\n",
    "\n",
    "# Define the complete ResNet-50 model with Self-Attention\n",
    "class ResNet50(nn.Module):\n",
    "    def __init__(self, input_channels=12, num_classes=2):\n",
    "        super(ResNet50, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(ResBlock1, 64, 128, 1)\n",
    "        self.layer2 = self._make_layer(ResBlock2, 128, 128, 2)\n",
    "        self.layer3 = self._make_layer(ResBlock1, 128, 256, 1)\n",
    "        self.layer4 = self._make_layer(ResBlock2, 256, 256, 3)\n",
    "        self.layer5 = self._make_layer(ResBlock1, 256, 512, 1)\n",
    "        self.layer6 = self._make_layer(ResBlock2, 512, 512, 5)\n",
    "        self.layer7 = self._make_layer(ResBlock1, 512, 1024, 1)\n",
    "        self.layer8 = self._make_layer(ResBlock2, 1024, 1024, 2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.dropout = nn.Dropout(p=0.5) #added to improve generalization\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "\n",
    "    def _make_layer(self, block, in_channels, out_channels, blocks):\n",
    "        layers = []\n",
    "        layers.append(block(in_channels, out_channels))\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "        x = self.layer7(x)\n",
    "        x = self.layer8(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = torch.squeeze(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model and print the summary\n",
    "model = ResNet50(input_channels=12, num_classes=1)\n",
    "\n",
    "# Check if CUDA is available and move the model to the GPU if it is\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_P3pWpWNGj7x"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True,num_workers=2)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True,num_workers=2)\n",
    "validation_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=True,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import math\n",
    "\n",
    "def lr_lambda(epoch):\n",
    "    if epoch < 10:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return math.exp(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rclVOfWEF8lt",
    "outputId": "cc132c7e-9ecb-4353-c11f-88ce1595e523"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 1/20, Loss: 0.4864, Accuracy: 0.7520\n",
      "Validation - Epoch 1/20, Loss: 0.4894, Accuracy: 0.7937\n",
      "Training - Epoch 2/20, Loss: 0.3613, Accuracy: 0.8500\n",
      "Validation - Epoch 2/20, Loss: 0.4462, Accuracy: 0.8022\n",
      "Training - Epoch 3/20, Loss: 0.3417, Accuracy: 0.8526\n",
      "Validation - Epoch 3/20, Loss: 0.4245, Accuracy: 0.7949\n",
      "Training - Epoch 4/20, Loss: 0.3271, Accuracy: 0.8606\n",
      "Validation - Epoch 4/20, Loss: 0.4134, Accuracy: 0.8215\n",
      "Training - Epoch 5/20, Loss: 0.2995, Accuracy: 0.8714\n",
      "Validation - Epoch 5/20, Loss: 0.4670, Accuracy: 0.8034\n",
      "Training - Epoch 6/20, Loss: 0.2800, Accuracy: 0.8826\n",
      "Validation - Epoch 6/20, Loss: 0.4722, Accuracy: 0.8251\n",
      "Training - Epoch 7/20, Loss: 0.2659, Accuracy: 0.8867\n",
      "Validation - Epoch 7/20, Loss: 0.5002, Accuracy: 0.8275\n",
      "Training - Epoch 8/20, Loss: 0.1980, Accuracy: 0.9259\n",
      "Validation - Epoch 8/20, Loss: 0.4430, Accuracy: 0.8323\n",
      "Training - Epoch 9/20, Loss: 0.1472, Accuracy: 0.9429\n",
      "Validation - Epoch 9/20, Loss: 0.4874, Accuracy: 0.8311\n",
      "Training - Epoch 10/20, Loss: 0.1220, Accuracy: 0.9533\n",
      "Validation - Epoch 10/20, Loss: 0.5505, Accuracy: 0.8215\n",
      "Training - Epoch 11/20, Loss: 0.0844, Accuracy: 0.9722\n",
      "Validation - Epoch 11/20, Loss: 0.5674, Accuracy: 0.8275\n",
      "Training - Epoch 12/20, Loss: 0.0608, Accuracy: 0.9808\n",
      "Validation - Epoch 12/20, Loss: 0.6661, Accuracy: 0.8215\n",
      "Training - Epoch 13/20, Loss: 0.0579, Accuracy: 0.9821\n",
      "Validation - Epoch 13/20, Loss: 0.6752, Accuracy: 0.8311\n",
      "Training - Epoch 14/20, Loss: 0.0317, Accuracy: 0.9916\n",
      "Validation - Epoch 14/20, Loss: 0.8134, Accuracy: 0.8215\n",
      "Training - Epoch 15/20, Loss: 0.0261, Accuracy: 0.9927\n",
      "Validation - Epoch 15/20, Loss: 0.7662, Accuracy: 0.8215\n",
      "Training - Epoch 16/20, Loss: 0.0256, Accuracy: 0.9929\n",
      "Validation - Epoch 16/20, Loss: 0.8118, Accuracy: 0.8215\n",
      "Training - Epoch 17/20, Loss: 0.0227, Accuracy: 0.9937\n",
      "Validation - Epoch 17/20, Loss: 0.7800, Accuracy: 0.8203\n",
      "Training - Epoch 18/20, Loss: 0.0207, Accuracy: 0.9951\n",
      "Validation - Epoch 18/20, Loss: 0.8376, Accuracy: 0.8203\n",
      "Training - Epoch 19/20, Loss: 0.0155, Accuracy: 0.9965\n",
      "Validation - Epoch 19/20, Loss: 0.8650, Accuracy: 0.8191\n",
      "Training - Epoch 20/20, Loss: 0.0129, Accuracy: 0.9979\n",
      "Validation - Epoch 20/20, Loss: 0.8386, Accuracy: 0.8166\n",
      "Training complete. Best validation accuracy: 0.8323\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import copy\n",
    "\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001) \n",
    "# scheduler = LambdaLR(optimizer, lr_lambda)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "num_epochs = 20\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_acc = 0.0\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "import copy\n",
    "\n",
    "# Assuming you have defined your model, criterion, optimizer, scheduler, num_epochs, best_model_wts, and best_acc\n",
    "\n",
    "# Define your validation function\n",
    "def validate_model(model, dataloader, criterion):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.float()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.round(outputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for inputs, labels in train_dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels = labels.float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.round(outputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataloader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(train_dataloader.dataset)\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f'Training - Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
    "\n",
    "    # Validate the model\n",
    "    val_loss, val_acc = validate_model(model, validation_dataloader, criterion)\n",
    "    print(f'Validation - Epoch {epoch+1}/{num_epochs}, Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}')\n",
    "\n",
    "    # Deep copy the model if the current validation accuracy is the best so far\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        # Save the best model\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "\n",
    "# Load best model weights\n",
    "model.load_state_dict(best_model_wts)\n",
    "\n",
    "print(f\"Training complete. Best validation accuracy: {best_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P08h1mCVhVPI",
    "outputId": "977f2580-2673-4d9d-b400-24e941f2b885"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8645320197044335\n",
      "Confusion Matrix:\n",
      "[[307  34]\n",
      " [ 76 395]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "model = ResNet50(input_channels=12, num_classes=1)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, labels in test_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            outputs = model(data)\n",
    "            preds = torch.round(outputs)\n",
    "            preds = preds.int()\n",
    "            # _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    return accuracy, cm\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `model` is your PyTorch model and `test_loader` is your test data loader\n",
    "accuracy, confusion_matrix = test_model(model, test_dataloader)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 549
    },
    "id": "IpeF9mgyldMf",
    "outputId": "da2cda34-7052-4eb0-8324-61dfe3b7fba3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
