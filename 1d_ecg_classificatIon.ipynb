{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jyIMzGSA-_oZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.signal import butter, filtfilt\n",
    "import wfdb\n",
    "import pandas as pd\n",
    "import sys\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "A43FYGHX_iX-"
   },
   "outputs": [],
   "source": [
    "#definition of data path and excel file path\n",
    "path = '/home/abhishek/rashad_internship/Physionet/ptb-xl-1.0.3/'\n",
    "excel = '/home/abhishek/rashad_internship/Physionet/ptb-xl-1.0.3/ptbxl_database.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tozT3NrF_kAl"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from scipy.signal import butter, filtfilt\n",
    "import wfdb\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "class Custom_class(Dataset):\n",
    "    def __init__(self, path, num_data, transform=None, data_split='train', fold=10):\n",
    "        self.dat = pd.read_csv(path + 'ptbxl_database.csv',index_col='ecg_id')\n",
    "        self.statements = pd.read_csv(path + 'scp_statements.csv', index_col=0)\n",
    "        self.statements = self.statements[self.statements.diagnostic == 1]\n",
    "        self.dat.index = self.dat.index.astype(int)\n",
    "        self.dat.index = self.dat.reindex(range(0, 21799))\n",
    "        \n",
    "        # Add diagnostic superclass\n",
    "        self.dat.scp_codes = self.dat.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "        self.dat['diagnostic_superclass'] = self.dat.scp_codes.apply(self.aggregate_diagnostic)\n",
    "        \n",
    "        self.col = self.dat['filename_hr']  # only 500 hz files are used for training\n",
    "        self.label = self.dat['scp_codes']  # used for labeling\n",
    "        self.superclass_label = self.dat['diagnostic_superclass']  # diagnostic superclass label\n",
    "        self.strat_fold = self.dat['strat_fold']  # Load strat_fold column\n",
    "        self.path = path\n",
    "        self.transform = transform  # Initialize the transform attribute\n",
    "        self.num_data = num_data\n",
    "        self.data_split = data_split\n",
    "        self.fold = fold\n",
    "        \n",
    "        if self.data_split == 'train':\n",
    "            self.indices = [idx for idx in range(self.num_data) if (self.strat_fold[idx] <= self.fold)]\n",
    "        elif self.data_split == 'test':\n",
    "            self.indices = [idx for idx in range(self.num_data) if (self.strat_fold[idx] == self.fold)]\n",
    "        elif self.data_split == 'val':\n",
    "            self.indices = [idx for idx in range(self.num_data) if (self.strat_fold[idx] == self.fold)]\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = self.indices[idx]  # Adjust index to match filtered data\n",
    "        \n",
    "        y, _ = wfdb.rdsamp(self.path + self.col[idx])  # Use channel 0\n",
    "        y = y.astype(np.float32)\n",
    "        y = np.transpose(y)  # changing dimension from 5000, 12 to 12, 5000\n",
    "\n",
    "        # Apply filtering\n",
    "        y = self.bandpass_filter(y, 1, 47, 500)  # applying BPF\n",
    "\n",
    "        # Normalize using z-score\n",
    "        y = self.z_score_normalize(y)\n",
    "        y = y.astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "        # Get the diagnostic superclass label\n",
    "        superclass_list = self.superclass_label[idx]\n",
    "\n",
    "        # Determine label based on superclass list\n",
    "        if len(superclass_list) == 0 or len(superclass_list) > 1:\n",
    "            label = 1  # If superclass list is empty or contains more than one item, label as 1\n",
    "        else:\n",
    "            if superclass_list[0] == 'NORM':\n",
    "                label = 0  # If superclass contains only 'NORM', label as 0\n",
    "            else:\n",
    "                label = 1 \n",
    "\n",
    "        if self.transform:\n",
    "            y = self.transform(y)\n",
    "        \n",
    "\n",
    "        return y[0, :, :],  label\n",
    "\n",
    "    def bandpass_filter(self, data, lowcut, highcut, fs, order=3):\n",
    "        nyquist = 0.5 * fs\n",
    "        low = lowcut / nyquist\n",
    "        high = highcut / nyquist\n",
    "        b, a = butter(order, [low, high], btype='band')\n",
    "        y = filtfilt(b, a, data, axis=1)\n",
    "        return y\n",
    "\n",
    "    def z_score_normalize(self, data):\n",
    "        mean = np.mean(data, axis=1, keepdims=True)\n",
    "        std = np.std(data, axis=1, keepdims=True)\n",
    "        normalized_data = (data - mean) / std\n",
    "        return normalized_data\n",
    "\n",
    "    def aggregate_diagnostic(self, y_dic):\n",
    "        tmp = []\n",
    "        for key in y_dic.keys():\n",
    "            if key in self.statements.index:\n",
    "                tmp.append(self.statements.loc[key].diagnostic_class)\n",
    "        return list(set(tmp))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = Custom_class(path, num_data=7000, transform=transform, data_split='train',fold=8)\n",
    "\n",
    "\n",
    "# For test data\n",
    "test_dataset = Custom_class(path, num_data=7000, transform=transform, data_split='test',fold=10)\n",
    "\n",
    "# For validation data\n",
    "val_dataset = Custom_class( path, num_data=7000, transform=transform, data_split='val',fold=9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data in Training set : 5359\n",
      "Number of data in Validation set :812\n",
      "Number of data in Test set : 829\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of data in Training set : {len(train_dataset)}\")\n",
    "print(f\"Number of data in Validation set :{len(val_dataset)}\")\n",
    "print(f\"Number of data in Test set : {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "XI7KUi3h_-iL"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "# Define the Shannon Entropy calculation function\n",
    "def shannon_entropy(x):\n",
    "    B, C, T = x.size()\n",
    "    entropies = torch.zeros(B, C).to(x.device)\n",
    "    epsilon = 1e-10\n",
    "    for b in range(B):\n",
    "        for c in range(C):\n",
    "            total_sum = x[b, c, :].sum()\n",
    "            if total_sum == 0:\n",
    "                continue  # Skip channels with zero sum to avoid division by zero\n",
    "            p = x[b, c, :] / total_sum\n",
    "            p = p.clamp(min=epsilon)  # Clamp probabilities to avoid log(0)\n",
    "            entropies[b, c] = -torch.sum(p * torch.log2(p))\n",
    "    return entropies\n",
    "\n",
    "# Define the Res_Block_1\n",
    "class ResBlock1(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResBlock1, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=2, stride=2, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv3 = nn.Conv1d(out_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm1d(out_channels)\n",
    "        self.adjust_channels = nn.Conv1d(in_channels, out_channels, kernel_size=2, stride=2, padding=1)\n",
    "        self.adjust_bn = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.adjust_channels(x)\n",
    "        shortcut = self.adjust_bn(shortcut)\n",
    "\n",
    "        x = F.leaky_relu(self.bn1(self.conv1(x)))\n",
    "        x = F.leaky_relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = x + shortcut\n",
    "        x = F.leaky_relu(x)\n",
    "        return x\n",
    "\n",
    "# Define the Res_Block_2\n",
    "class ResBlock2(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResBlock2, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv3 = nn.Conv1d(out_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm1d(out_channels)\n",
    "        self.adjust_channels = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.adjust_bn = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.adjust_channels(x)\n",
    "        shortcut = self.adjust_bn(shortcut)\n",
    "\n",
    "        x = F.leaky_relu(self.bn1(self.conv1(x)))\n",
    "        x = F.leaky_relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = x + shortcut\n",
    "        x = F.leaky_relu(x)\n",
    "        return x\n",
    "\n",
    "# Define the complete ResNet-50 model with Self-Attention\n",
    "class ResNet50(nn.Module):\n",
    "    def __init__(self, input_channels=12, num_classes=2):\n",
    "        super(ResNet50, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(ResBlock1, 64, 128, 1)\n",
    "        self.layer2 = self._make_layer(ResBlock2, 128, 128, 2)\n",
    "        self.layer3 = self._make_layer(ResBlock1, 128, 256, 1)\n",
    "        self.layer4 = self._make_layer(ResBlock2, 256, 256, 3)\n",
    "        self.layer5 = self._make_layer(ResBlock1, 256, 512, 1)\n",
    "        self.layer6 = self._make_layer(ResBlock2, 512, 512, 5)\n",
    "        self.layer7 = self._make_layer(ResBlock1, 512, 1024, 1)\n",
    "        self.layer8 = self._make_layer(ResBlock2, 1024, 1024, 2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.dropout = nn.Dropout(p=0.5)  # added to improve generalization\n",
    "        self.fc1 = nn.Linear(1024, 512)  # 1024 (features) + 12 (entropies)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "\n",
    "    def _make_layer(self, block, in_channels, out_channels, blocks):\n",
    "        layers = []\n",
    "        layers.append(block(in_channels, out_channels))\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # entropy = shannon_entropy(x)  # Compute the entropy\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "        x = self.layer7(x)\n",
    "        x = self.layer8(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # x = torch.cat((x, entropy), dim=1)  # Concatenate the entropy to the features\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = torch.squeeze(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model and print the summary\n",
    "model = ResNet50(input_channels=12, num_classes=1)\n",
    "\n",
    "# Check if CUDA is available and move the model to the GPU if it is\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_P3pWpWNGj7x"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True,num_workers=2)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True,num_workers=2)\n",
    "validation_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=True,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import math\n",
    "\n",
    "def lr_lambda(epoch):\n",
    "    if epoch < 10:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return math.exp(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rclVOfWEF8lt",
    "outputId": "cc132c7e-9ecb-4353-c11f-88ce1595e523"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/20: 100%|██████████| 168/168 [00:20<00:00,  8.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 1/20, Loss: 0.5007, Accuracy: 0.7365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 1/20, Loss: 0.4069, Accuracy: 0.8300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/20: 100%|██████████| 168/168 [00:18<00:00,  9.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 2/20, Loss: 0.3813, Accuracy: 0.8336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 2/20, Loss: 0.3771, Accuracy: 0.8313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/20: 100%|██████████| 168/168 [00:18<00:00,  9.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 3/20, Loss: 0.3573, Accuracy: 0.8490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 3/20, Loss: 0.3573, Accuracy: 0.8522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/20: 100%|██████████| 168/168 [00:18<00:00,  9.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 4/20, Loss: 0.3233, Accuracy: 0.8625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 4/20, Loss: 0.3310, Accuracy: 0.8436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/20: 100%|██████████| 168/168 [00:18<00:00,  9.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 5/20, Loss: 0.3063, Accuracy: 0.8716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 5/20, Loss: 0.3565, Accuracy: 0.8534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/20: 100%|██████████| 168/168 [00:18<00:00,  9.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 6/20, Loss: 0.2864, Accuracy: 0.8783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 6/20, Loss: 0.3299, Accuracy: 0.8534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/20: 100%|██████████| 168/168 [00:18<00:00,  9.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 7/20, Loss: 0.2784, Accuracy: 0.8841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 7/20, Loss: 0.3592, Accuracy: 0.8596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/20: 100%|██████████| 168/168 [00:19<00:00,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 8/20, Loss: 0.2640, Accuracy: 0.8949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 8/20, Loss: 0.3305, Accuracy: 0.8498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/20: 100%|██████████| 168/168 [00:18<00:00,  9.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 9/20, Loss: 0.2466, Accuracy: 0.8962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 9/20, Loss: 0.3594, Accuracy: 0.8596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/20: 100%|██████████| 168/168 [00:18<00:00,  9.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 10/20, Loss: 0.2304, Accuracy: 0.9026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 10/20, Loss: 0.3799, Accuracy: 0.8633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/20: 100%|██████████| 168/168 [00:18<00:00,  9.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 11/20, Loss: 0.1436, Accuracy: 0.9422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 11/20, Loss: 0.4668, Accuracy: 0.8584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/20: 100%|██████████| 168/168 [00:18<00:00,  9.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 12/20, Loss: 0.0968, Accuracy: 0.9644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 12/20, Loss: 0.5921, Accuracy: 0.8498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13/20: 100%|██████████| 168/168 [00:18<00:00,  9.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 13/20, Loss: 0.0962, Accuracy: 0.9659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 13/20, Loss: 0.5560, Accuracy: 0.8571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14/20: 100%|██████████| 168/168 [00:18<00:00,  8.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 14/20, Loss: 0.0810, Accuracy: 0.9707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 14/20, Loss: 0.5684, Accuracy: 0.8596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15/20: 100%|██████████| 168/168 [00:18<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 15/20, Loss: 0.0644, Accuracy: 0.9757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 15/20, Loss: 0.6398, Accuracy: 0.8596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16/20: 100%|██████████| 168/168 [00:19<00:00,  8.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 16/20, Loss: 0.0571, Accuracy: 0.9789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 16/20, Loss: 0.6351, Accuracy: 0.8633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17/20: 100%|██████████| 168/168 [00:18<00:00,  9.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 17/20, Loss: 0.0465, Accuracy: 0.9825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 17/20, Loss: 0.6162, Accuracy: 0.8571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18/20: 100%|██████████| 168/168 [00:18<00:00,  9.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 18/20, Loss: 0.0419, Accuracy: 0.9836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 18/20, Loss: 0.6441, Accuracy: 0.8670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19/20: 100%|██████████| 168/168 [00:18<00:00,  9.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 19/20, Loss: 0.0391, Accuracy: 0.9877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 19/20, Loss: 0.7106, Accuracy: 0.8596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20/20: 100%|██████████| 168/168 [00:18<00:00,  9.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 20/20, Loss: 0.0333, Accuracy: 0.9884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 20/20, Loss: 0.7198, Accuracy: 0.8719\n",
      "Training complete. Best validation accuracy: 0.8719\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "# Assuming you have defined your model, train_dataloader, validation_dataloader, device, etc.\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001) \n",
    "# scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "\n",
    "num_epochs = 20\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_acc = 0.0\n",
    "\n",
    "# Define your validation function\n",
    "def validate_model(model, dataloader, criterion):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc=\"Validation\", leave=False):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.float()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.round(outputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for inputs, labels in tqdm(train_dataloader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\"):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels = labels.float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.round(outputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataloader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(train_dataloader.dataset)\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f'Training - Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
    "\n",
    "    # Validate the model\n",
    "    val_loss, val_acc = validate_model(model, validation_dataloader, criterion)\n",
    "    print(f'Validation - Epoch {epoch+1}/{num_epochs}, Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}')\n",
    "\n",
    "    # Deep copy the model if the current validation accuracy is the best so far\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        # Save the best model\n",
    "        torch.save(model.state_dict(), \"best_model_fold_8.pth\")\n",
    "\n",
    "# Load best model weights\n",
    "model.load_state_dict(best_model_wts)\n",
    "\n",
    "print(f\"Training complete. Best validation accuracy: {best_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def is_number(x):\n",
    "    try:\n",
    "        float(x)\n",
    "        return True\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "\n",
    "def is_nan(x):\n",
    "    if is_number(x):\n",
    "        return np.isnan(float(x))\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def compute_one_hot_encoding(data, num_classes):\n",
    "    num_instances = len(data)\n",
    "    one_hot_encoding = np.zeros((num_instances, num_classes), dtype=np.bool_)\n",
    "    for i, x in enumerate(data):\n",
    "        if is_number(x) and not is_nan(x):\n",
    "            one_hot_encoding[i, int(x)] = 1\n",
    "    return one_hot_encoding\n",
    "\n",
    "def compute_one_vs_rest_confusion_matrix(labels, outputs, num_classes):\n",
    "    assert np.shape(labels) == np.shape(outputs)\n",
    "\n",
    "    num_instances = len(labels)\n",
    "    A = np.zeros((num_classes, 2, 2))\n",
    "    for i in range(num_instances):\n",
    "        for j in range(num_classes):\n",
    "            if labels[i, j] == 1 and outputs[i, j] == 1: # TP\n",
    "                A[j, 0, 0] += 1\n",
    "            elif labels[i, j] == 0 and outputs[i, j] == 1: # FP\n",
    "                A[j, 0, 1] += 1\n",
    "            elif labels[i, j] == 1 and outputs[i, j] == 0: # FN\n",
    "                A[j, 1, 0] += 1\n",
    "            elif labels[i, j] == 0 and outputs[i, j] == 0: # TN\n",
    "                A[j, 1, 1] += 1\n",
    "\n",
    "    return A\n",
    "\n",
    "# Compute macro F-measure.\n",
    "def compute_f_measure(labels, outputs):\n",
    "    # Find the number of classes.\n",
    "    classes = sorted(set(labels) | set(outputs))\n",
    "    num_classes = len(classes)\n",
    "\n",
    "    # Convert labels and outputs to one-hot encoded format.\n",
    "    labels_one_hot = compute_one_hot_encoding(labels, num_classes)\n",
    "    outputs_one_hot = compute_one_hot_encoding(outputs, num_classes)\n",
    "\n",
    "    # Compute confusion matrix.\n",
    "    A = compute_one_vs_rest_confusion_matrix(labels_one_hot, outputs_one_hot, num_classes)\n",
    "\n",
    "    per_class_f_measure = np.zeros(num_classes)\n",
    "    for k in range(num_classes):\n",
    "        tp, fp, fn, tn = A[k, 0, 0], A[k, 0, 1], A[k, 1, 0], A[k, 1, 1]\n",
    "        if 2 * tp + fp + fn > 0:\n",
    "            per_class_f_measure[k] = float(2 * tp) / float(2 * tp + fp + fn)\n",
    "        else:\n",
    "            per_class_f_measure[k] = float('nan')\n",
    "\n",
    "    if np.any(np.isfinite(per_class_f_measure)):\n",
    "        macro_f_measure = np.nanmean(per_class_f_measure)\n",
    "    else:\n",
    "        macro_f_measure = float('nan')\n",
    "\n",
    "    return macro_f_measure, per_class_f_measure, classes\n",
    "\n",
    "# Example usage\n",
    "# labels = [0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1]\n",
    "# outputs = [0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1]\n",
    "\n",
    "# macro_f_measure, per_class_f_measure, classes = compute_f_measure(labels, outputs)\n",
    "# print(\"Macro F-Measure:\", macro_f_measure)\n",
    "# print(\"Per Class F-Measure:\", per_class_f_measure)\n",
    "# print(\"Classes:\", classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P08h1mCVhVPI",
    "outputId": "977f2580-2673-4d9d-b400-24e941f2b885"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8238841978287093\n",
      "AUC Score: 0.888553085608319\n",
      "F1 Score: 0.832183908045977\n",
      "Precision: 0.8660287081339713\n",
      "Specificity: 0.8514588859416445\n",
      "F Measure :  0.8234523601143591\n",
      "Normal Class F Measure :  0.8147208121827412\n",
      "AbNormal Class F Measure :  0.832183908045977\n",
      "Confusion Matrix:\n",
      "[[321  56]\n",
      " [ 90 362]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, f1_score, precision_score\n",
    "\n",
    "model = ResNet50(input_channels=12, num_classes=1)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load('/home/abhishek/rashad_internship/ecg_classification_using_resnet/best_model_fold_8.pth'))\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_preds_1 = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, labels in test_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            outputs = model(data)\n",
    "            all_preds_1.extend(outputs.cpu().numpy())\n",
    "            preds = torch.round(outputs)\n",
    "            preds = preds.int()\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    # Calculate AUC\n",
    "    auc = roc_auc_score(all_labels, all_preds_1)\n",
    "\n",
    "    # Calculate F1 Score\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "    # Calculate Precision\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "\n",
    "    # Calculate Specificity\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    macro_f_measure, per_class_f_measure, classes = compute_f_measure(all_labels,all_preds)\n",
    "\n",
    "    return accuracy, cm, auc, f1, precision, specificity,macro_f_measure, per_class_f_measure, classes\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `model` is your PyTorch model and `test_loader` is your test data loader\n",
    "accuracy, cm, auc, f1, precision, specificity,macro_f_measure, per_class_f_measure, classes = test_model(model, test_dataloader)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"AUC Score:\", auc)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"F Measure : \",macro_f_measure)\n",
    "print(\"Normal Class F Measure : \",per_class_f_measure[0])\n",
    "print(\"AbNormal Class F Measure : \",per_class_f_measure[1])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 549
    },
    "id": "IpeF9mgyldMf",
    "outputId": "da2cda34-7052-4eb0-8324-61dfe3b7fba3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
