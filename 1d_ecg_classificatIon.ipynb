{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jyIMzGSA-_oZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.signal import butter, filtfilt\n",
    "import wfdb\n",
    "import pandas as pd\n",
    "import sys\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "A43FYGHX_iX-"
   },
   "outputs": [],
   "source": [
    "#definition of data path and excel file path\n",
    "path = '/home/abhishek/rashad_internship/Physionet/ptb-xl-1.0.3/'\n",
    "excel = '/home/abhishek/rashad_internship/Physionet/ptb-xl-1.0.3/ptbxl_database.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tozT3NrF_kAl"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from scipy.signal import butter, filtfilt\n",
    "import wfdb\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "class Custom_class(Dataset):\n",
    "    def __init__(self, path, num_data, transform=None, data_split='train', fold=10):\n",
    "        self.dat = pd.read_csv(path + 'ptbxl_database.csv',index_col='ecg_id')\n",
    "        self.statements = pd.read_csv(path + 'scp_statements.csv', index_col=0)\n",
    "        self.statements = self.statements[self.statements.diagnostic == 1]\n",
    "        self.dat.index = self.dat.index.astype(int)\n",
    "        self.dat.index = self.dat.reindex(range(0, 21799))\n",
    "        \n",
    "        # Add diagnostic superclass\n",
    "        self.dat.scp_codes = self.dat.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "        self.dat['diagnostic_superclass'] = self.dat.scp_codes.apply(self.aggregate_diagnostic)\n",
    "        self.dat = self.dat[self.dat['diagnostic_superclass'].apply(lambda x: len(x) > 0)]\n",
    "        \n",
    "        self.col = self.dat['filename_hr']  # only 500 hz files are used for training\n",
    "        self.label = self.dat['scp_codes']  # used for labeling\n",
    "        self.superclass_label = self.dat['diagnostic_superclass']  # diagnostic superclass label\n",
    "        self.strat_fold = self.dat['strat_fold']  # Load strat_fold column\n",
    "        self.path = path\n",
    "        self.transform = transform  # Initialize the transform attribute\n",
    "        self.num_data = num_data\n",
    "        self.data_split = data_split\n",
    "        self.fold = fold\n",
    "        \n",
    "        if self.data_split == 'train':\n",
    "            self.indices = [idx for idx in range(self.num_data) if (self.strat_fold[idx] <= self.fold)]\n",
    "        elif self.data_split == 'test':\n",
    "            self.indices = [idx for idx in range(self.num_data) if (self.strat_fold[idx] == self.fold)]\n",
    "        elif self.data_split == 'val':\n",
    "            self.indices = [idx for idx in range(self.num_data) if (self.strat_fold[idx] == self.fold)]\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = self.indices[idx]  # Adjust index to match filtered data\n",
    "        \n",
    "        y, _ = wfdb.rdsamp(self.path + self.col[idx])  # Use channel 0\n",
    "        y = y.astype(np.float32)\n",
    "        y = np.transpose(y)  # changing dimension from 5000, 12 to 12, 5000\n",
    "\n",
    "        # Apply filtering\n",
    "        y = self.bandpass_filter(y, 1, 47, 500)  # applying BPF\n",
    "\n",
    "        # Normalize using z-score\n",
    "        y = self.z_score_normalize(y)\n",
    "        y = y.astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "        # Get the diagnostic superclass label\n",
    "        superclass_list = self.superclass_label[idx]\n",
    "\n",
    "        # Determine label based on superclass list\n",
    "        if len(superclass_list) == 0 or len(superclass_list) > 1:\n",
    "            label = 1  # If superclass list is empty or contains more than one item, label as 1\n",
    "        else:\n",
    "            if superclass_list[0] == 'NORM':\n",
    "                label = 0  # If superclass contains only 'NORM', label as 0\n",
    "            else:\n",
    "                label = 1 \n",
    "\n",
    "        if self.transform:\n",
    "            y = self.transform(y)\n",
    "        \n",
    "\n",
    "        return y[0, :, :],  label\n",
    "\n",
    "    def bandpass_filter(self, data, lowcut, highcut, fs, order=3):\n",
    "        nyquist = 0.5 * fs\n",
    "        low = lowcut / nyquist\n",
    "        high = highcut / nyquist\n",
    "        b, a = butter(order, [low, high], btype='band')\n",
    "        y = filtfilt(b, a, data, axis=1)\n",
    "        return y\n",
    "\n",
    "    def z_score_normalize(self, data):\n",
    "        mean = np.mean(data, axis=1, keepdims=True)\n",
    "        std = np.std(data, axis=1, keepdims=True)\n",
    "        normalized_data = (data - mean) / std\n",
    "        return normalized_data\n",
    "\n",
    "    def aggregate_diagnostic(self, y_dic):\n",
    "        tmp = []\n",
    "        for key in y_dic.keys():\n",
    "            if key in self.statements.index:\n",
    "                tmp.append(self.statements.loc[key].diagnostic_class)\n",
    "        return list(set(tmp))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = Custom_class(path, num_data=7000, transform=transform, data_split='train',fold=8)\n",
    "\n",
    "\n",
    "# For test data\n",
    "test_dataset = Custom_class(path, num_data=7000, transform=transform, data_split='test',fold=10)\n",
    "\n",
    "# For validation data\n",
    "val_dataset = Custom_class( path, num_data=7000, transform=transform, data_split='val',fold=9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data in Training set : 5368\n",
      "Number of data in Validation set :803\n",
      "Number of data in Test set : 829\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of data in Training set : {len(train_dataset)}\")\n",
    "print(f\"Number of data in Validation set :{len(val_dataset)}\")\n",
    "print(f\"Number of data in Test set : {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XI7KUi3h_-iL"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "# Define the Shannon Entropy calculation function\n",
    "def shannon_entropy(x):\n",
    "    B, C, T = x.size()\n",
    "    entropies = torch.zeros(B, C).to(x.device)\n",
    "    epsilon = 1e-10\n",
    "    for b in range(B):\n",
    "        for c in range(C):\n",
    "            total_sum = x[b, c, :].sum()\n",
    "            if total_sum == 0:\n",
    "                continue  # Skip channels with zero sum to avoid division by zero\n",
    "            p = x[b, c, :] / total_sum\n",
    "            p = p.clamp(min=epsilon)  # Clamp probabilities to avoid log(0)\n",
    "            entropies[b, c] = -torch.sum(p * torch.log2(p))\n",
    "    return entropies\n",
    "\n",
    "# Define the Res_Block_1\n",
    "class ResBlock1(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResBlock1, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=2, stride=2, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv3 = nn.Conv1d(out_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm1d(out_channels)\n",
    "        self.adjust_channels = nn.Conv1d(in_channels, out_channels, kernel_size=2, stride=2, padding=1)\n",
    "        self.adjust_bn = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.adjust_channels(x)\n",
    "        shortcut = self.adjust_bn(shortcut)\n",
    "\n",
    "        x = F.leaky_relu(self.bn1(self.conv1(x)))\n",
    "        x = F.leaky_relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = x + shortcut\n",
    "        x = F.leaky_relu(x)\n",
    "        return x\n",
    "\n",
    "# Define the Res_Block_2\n",
    "class ResBlock2(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResBlock2, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv3 = nn.Conv1d(out_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm1d(out_channels)\n",
    "        self.adjust_channels = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.adjust_bn = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.adjust_channels(x)\n",
    "        shortcut = self.adjust_bn(shortcut)\n",
    "\n",
    "        x = F.leaky_relu(self.bn1(self.conv1(x)))\n",
    "        x = F.leaky_relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = x + shortcut\n",
    "        x = F.leaky_relu(x)\n",
    "        return x\n",
    "\n",
    "# Define the complete ResNet-50 model with Self-Attention\n",
    "class ResNet50(nn.Module):\n",
    "    def __init__(self, input_channels=12, num_classes=2):\n",
    "        super(ResNet50, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(ResBlock1, 64, 128, 1)\n",
    "        self.layer2 = self._make_layer(ResBlock2, 128, 128, 2)\n",
    "        self.layer3 = self._make_layer(ResBlock1, 128, 256, 1)\n",
    "        self.layer4 = self._make_layer(ResBlock2, 256, 256, 3)\n",
    "        self.layer5 = self._make_layer(ResBlock1, 256, 512, 1)\n",
    "        self.layer6 = self._make_layer(ResBlock2, 512, 512, 5)\n",
    "        self.layer7 = self._make_layer(ResBlock1, 512, 1024, 1)\n",
    "        self.layer8 = self._make_layer(ResBlock2, 1024, 1024, 2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.dropout = nn.Dropout(p=0.5)  # added to improve generalization\n",
    "        self.fc1 = nn.Linear(1024, 512)  # 1024 (features) + 12 (entropies)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "\n",
    "    def _make_layer(self, block, in_channels, out_channels, blocks):\n",
    "        layers = []\n",
    "        layers.append(block(in_channels, out_channels))\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # entropy = shannon_entropy(x)  # Compute the entropy\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "        x = self.layer7(x)\n",
    "        x = self.layer8(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # x = torch.cat((x, entropy), dim=1)  # Concatenate the entropy to the features\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = torch.squeeze(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model and print the summary\n",
    "model = ResNet50(input_channels=12, num_classes=1)\n",
    "\n",
    "# Check if CUDA is available and move the model to the GPU if it is\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_P3pWpWNGj7x"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True,num_workers=2)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True,num_workers=2)\n",
    "validation_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=True,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import math\n",
    "\n",
    "def lr_lambda(epoch):\n",
    "    if epoch < 10:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return math.exp(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TMSELoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Tangential Mean Squared Error Loss function.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(TMSELoss, self).__init__()\n",
    "    \n",
    "    def forward(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        squared_error = error ** 2\n",
    "        tan_squared_error = torch.tan(squared_error)\n",
    "        loss = torch.mean(tan_squared_error)\n",
    "        return loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rclVOfWEF8lt",
    "outputId": "cc132c7e-9ecb-4353-c11f-88ce1595e523"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:8qer6jtq) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e88035ec4644069b8062741016a373a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.014 MB of 0.014 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training Accuracy</td><td>▁▄▄▅▅▅▅▆▆▆▇█████████</td></tr><tr><td>Training Loss</td><td>█▆▆▅▅▅▄▄▄▄▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▅▁▄▆▇█▆▄▆▆█▇▇▇▅▄▆▆▆▆</td></tr><tr><td>Validation Loss</td><td>▂▄▂▁▂▁▂▂▁▂▂▅▅▆▆▅▆█▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training Accuracy</td><td>0.99162</td></tr><tr><td>Training Loss</td><td>0.0253</td></tr><tr><td>Validation Accuracy</td><td>0.85554</td></tr><tr><td>Validation Loss</td><td>0.65169</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ancient-shadow-2</strong> at: <a href='https://wandb.ai/rashadkp99/ecg_classification_final_run/runs/8qer6jtq' target=\"_blank\">https://wandb.ai/rashadkp99/ecg_classification_final_run/runs/8qer6jtq</a><br/> View project at: <a href='https://wandb.ai/rashadkp99/ecg_classification_final_run' target=\"_blank\">https://wandb.ai/rashadkp99/ecg_classification_final_run</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240711_125630-8qer6jtq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:8qer6jtq). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e981cbf78b469fa06d8aac17737f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113769389016346, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/abhishek/rashad_internship/ecg_classification_using_resnet/wandb/run-20240711_130808-02zvxd2c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rashadkp99/ecg_classification_final_run/runs/02zvxd2c' target=\"_blank\">earthy-cloud-3</a></strong> to <a href='https://wandb.ai/rashadkp99/ecg_classification_final_run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rashadkp99/ecg_classification_final_run' target=\"_blank\">https://wandb.ai/rashadkp99/ecg_classification_final_run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rashadkp99/ecg_classification_final_run/runs/02zvxd2c' target=\"_blank\">https://wandb.ai/rashadkp99/ecg_classification_final_run/runs/02zvxd2c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/20: 100%|██████████| 168/168 [00:19<00:00,  8.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 1/20, Loss: 0.0879, Accuracy: 0.8918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 1/20, Loss: 0.1181, Accuracy: 0.8593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/20: 100%|██████████| 168/168 [00:20<00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 2/20, Loss: 0.0791, Accuracy: 0.9041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 2/20, Loss: 0.1254, Accuracy: 0.8481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/20: 100%|██████████| 168/168 [00:18<00:00,  9.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 3/20, Loss: 0.0717, Accuracy: 0.9180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 3/20, Loss: 0.1377, Accuracy: 0.8518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/20: 100%|██████████| 168/168 [00:18<00:00,  9.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 4/20, Loss: 0.0719, Accuracy: 0.9143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 4/20, Loss: 0.1155, Accuracy: 0.8580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/20: 100%|██████████| 168/168 [00:19<00:00,  8.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 5/20, Loss: 0.0624, Accuracy: 0.9277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 5/20, Loss: 0.1500, Accuracy: 0.8406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/20: 100%|██████████| 168/168 [00:18<00:00,  9.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 6/20, Loss: 0.0568, Accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 6/20, Loss: 0.1525, Accuracy: 0.8443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/20: 100%|██████████| 168/168 [00:18<00:00,  9.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 7/20, Loss: 0.0521, Accuracy: 0.9378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 7/20, Loss: 0.1375, Accuracy: 0.8481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/20: 100%|██████████| 168/168 [00:18<00:00,  9.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 8/20, Loss: 0.0467, Accuracy: 0.9443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 8/20, Loss: 0.1408, Accuracy: 0.8493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/20: 100%|██████████| 168/168 [00:18<00:00,  8.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 9/20, Loss: 0.0383, Accuracy: 0.9564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 9/20, Loss: 0.1373, Accuracy: 0.8643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/20: 100%|██████████| 168/168 [00:18<00:00,  9.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 10/20, Loss: 0.0421, Accuracy: 0.9510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 10/20, Loss: 0.1606, Accuracy: 0.8369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/20: 100%|██████████| 168/168 [00:18<00:00,  9.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 11/20, Loss: 0.0170, Accuracy: 0.9836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 11/20, Loss: 0.1638, Accuracy: 0.8468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/20: 100%|██████████| 168/168 [00:18<00:00,  9.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 12/20, Loss: 0.0066, Accuracy: 0.9940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 12/20, Loss: 0.1645, Accuracy: 0.8630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13/20: 100%|██████████| 168/168 [00:18<00:00,  9.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 13/20, Loss: 0.0050, Accuracy: 0.9952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 13/20, Loss: 0.1731, Accuracy: 0.8493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14/20: 100%|██████████| 168/168 [00:18<00:00,  9.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 14/20, Loss: 0.0068, Accuracy: 0.9925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 14/20, Loss: 0.1689, Accuracy: 0.8580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15/20: 100%|██████████| 168/168 [00:18<00:00,  9.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 15/20, Loss: 0.0142, Accuracy: 0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 15/20, Loss: 0.1726, Accuracy: 0.8481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16/20: 100%|██████████| 168/168 [00:18<00:00,  9.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 16/20, Loss: 0.0085, Accuracy: 0.9911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 16/20, Loss: 0.1704, Accuracy: 0.8618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17/20: 100%|██████████| 168/168 [00:19<00:00,  8.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 17/20, Loss: 0.0047, Accuracy: 0.9948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 17/20, Loss: 0.1591, Accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18/20: 100%|██████████| 168/168 [00:18<00:00,  9.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 18/20, Loss: 0.0057, Accuracy: 0.9933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 18/20, Loss: 0.1794, Accuracy: 0.8531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19/20: 100%|██████████| 168/168 [00:19<00:00,  8.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 19/20, Loss: 0.0086, Accuracy: 0.9901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 19/20, Loss: 0.1714, Accuracy: 0.8543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20/20: 100%|██████████| 168/168 [00:18<00:00,  9.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 20/20, Loss: 0.0123, Accuracy: 0.9860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 20/20, Loss: 0.1855, Accuracy: 0.8456\n",
      "Training complete. Best validation accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import wandb\n",
    "\n",
    "# Initialize wandb\n",
    "wandb.init(project='ecg_classification_final_run')\n",
    "\n",
    "# Assuming you have defined your model, train_dataloader, validation_dataloader, device, etc.\n",
    "\n",
    "# criterion = nn.BCELoss()\n",
    "criterion = TMSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001) \n",
    "# scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "num_epochs = 20\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_acc = 0.0\n",
    "\n",
    "# Define your validation function\n",
    "def validate_model(model, dataloader, criterion):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc=\"Validation\", leave=False):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.float()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.round(outputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for inputs, labels in tqdm(train_dataloader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\"):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels = labels.float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.round(outputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataloader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(train_dataloader.dataset)\n",
    "    scheduler.step()\n",
    "\n",
    "    # Log training metrics to wandb\n",
    "    wandb.log({\n",
    "        'Training Loss': epoch_loss,\n",
    "        'Training Accuracy': epoch_acc,\n",
    "    })\n",
    "\n",
    "    print(f'Training - Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
    "\n",
    "    # Validate the model\n",
    "    val_loss, val_acc = validate_model(model, validation_dataloader, criterion)\n",
    "    print(f'Validation - Epoch {epoch+1}/{num_epochs}, Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}')\n",
    "\n",
    "    # Log validation metrics to wandb\n",
    "    wandb.log({\n",
    "        'Validation Loss': val_loss,\n",
    "        'Validation Accuracy': val_acc,\n",
    "    })\n",
    "\n",
    "    # Deep copy the model if the current validation accuracy is the best so far\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        # Save the best model\n",
    "        torch.save(model.state_dict(), \"best_model_fold_8.pth\")\n",
    "\n",
    "# Load best model weights\n",
    "model.load_state_dict(best_model_wts)\n",
    "\n",
    "print(f\"Training complete. Best validation accuracy: {best_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def is_number(x):\n",
    "    try:\n",
    "        float(x)\n",
    "        return True\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "\n",
    "def is_nan(x):\n",
    "    if is_number(x):\n",
    "        return np.isnan(float(x))\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def compute_one_hot_encoding(data, num_classes):\n",
    "    num_instances = len(data)\n",
    "    one_hot_encoding = np.zeros((num_instances, num_classes), dtype=np.bool_)\n",
    "    for i, x in enumerate(data):\n",
    "        if is_number(x) and not is_nan(x):\n",
    "            one_hot_encoding[i, int(x)] = 1\n",
    "    return one_hot_encoding\n",
    "\n",
    "def compute_one_vs_rest_confusion_matrix(labels, outputs, num_classes):\n",
    "    assert np.shape(labels) == np.shape(outputs)\n",
    "\n",
    "    num_instances = len(labels)\n",
    "    A = np.zeros((num_classes, 2, 2))\n",
    "    for i in range(num_instances):\n",
    "        for j in range(num_classes):\n",
    "            if labels[i, j] == 1 and outputs[i, j] == 1: # TP\n",
    "                A[j, 0, 0] += 1\n",
    "            elif labels[i, j] == 0 and outputs[i, j] == 1: # FP\n",
    "                A[j, 0, 1] += 1\n",
    "            elif labels[i, j] == 1 and outputs[i, j] == 0: # FN\n",
    "                A[j, 1, 0] += 1\n",
    "            elif labels[i, j] == 0 and outputs[i, j] == 0: # TN\n",
    "                A[j, 1, 1] += 1\n",
    "\n",
    "    return A\n",
    "\n",
    "# Compute macro F-measure.\n",
    "def compute_f_measure(labels, outputs):\n",
    "    # Find the number of classes.\n",
    "    classes = sorted(set(labels) | set(outputs))\n",
    "    num_classes = len(classes)\n",
    "\n",
    "    # Convert labels and outputs to one-hot encoded format.\n",
    "    labels_one_hot = compute_one_hot_encoding(labels, num_classes)\n",
    "    outputs_one_hot = compute_one_hot_encoding(outputs, num_classes)\n",
    "\n",
    "    # Compute confusion matrix.\n",
    "    A = compute_one_vs_rest_confusion_matrix(labels_one_hot, outputs_one_hot, num_classes)\n",
    "\n",
    "    per_class_f_measure = np.zeros(num_classes)\n",
    "    for k in range(num_classes):\n",
    "        tp, fp, fn, tn = A[k, 0, 0], A[k, 0, 1], A[k, 1, 0], A[k, 1, 1]\n",
    "        if 2 * tp + fp + fn > 0:\n",
    "            per_class_f_measure[k] = float(2 * tp) / float(2 * tp + fp + fn)\n",
    "        else:\n",
    "            per_class_f_measure[k] = float('nan')\n",
    "\n",
    "    if np.any(np.isfinite(per_class_f_measure)):\n",
    "        macro_f_measure = np.nanmean(per_class_f_measure)\n",
    "    else:\n",
    "        macro_f_measure = float('nan')\n",
    "\n",
    "    return macro_f_measure, per_class_f_measure, classes\n",
    "\n",
    "# Example usage\n",
    "# labels = [0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1]\n",
    "# outputs = [0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1]\n",
    "\n",
    "# macro_f_measure, per_class_f_measure, classes = compute_f_measure(labels, outputs)\n",
    "# print(\"Macro F-Measure:\", macro_f_measure)\n",
    "# print(\"Per Class F-Measure:\", per_class_f_measure)\n",
    "# print(\"Classes:\", classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P08h1mCVhVPI",
    "outputId": "977f2580-2673-4d9d-b400-24e941f2b885"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:84.1978287092883 %\n",
      "AUC Score: 0.8989501312335959\n",
      "F1 Score: 0.8502857142857143\n",
      "Precision: 0.8711943793911007\n",
      "Specificity: 0.8556430446194225\n",
      "F Measure :  0.8414902390074803\n",
      "Normal Class F Measure :  0.8326947637292464\n",
      "AbNormal Class F Measure :  0.8502857142857143\n",
      "Confusion Matrix:\n",
      "[[326  55]\n",
      " [ 76 372]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, f1_score, precision_score\n",
    "\n",
    "model = ResNet50(input_channels=12, num_classes=1)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load('/home/abhishek/rashad_internship/ecg_classification_using_resnet/best_model_fold_8.pth'))\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_preds_1 = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, labels in test_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            outputs = model(data)\n",
    "            all_preds_1.extend(outputs.cpu().numpy())\n",
    "            preds = torch.round(outputs)\n",
    "            preds = preds.int()\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    # Calculate AUC\n",
    "    auc = roc_auc_score(all_labels, all_preds_1)\n",
    "\n",
    "    # Calculate F1 Score\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "    # Calculate Precision\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "\n",
    "    # Calculate Specificity\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    macro_f_measure, per_class_f_measure, classes = compute_f_measure(all_labels,all_preds)\n",
    "\n",
    "    return accuracy, cm, auc, f1, precision, specificity,macro_f_measure, per_class_f_measure, classes\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `model` is your PyTorch model and `test_loader` is your test data loader\n",
    "accuracy, cm, auc, f1, precision, specificity,macro_f_measure, per_class_f_measure, classes = test_model(model, test_dataloader)\n",
    "print(f\"Accuracy:{ accuracy*100} %\")\n",
    "print(\"AUC Score:\", auc)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"F Measure : \",macro_f_measure)\n",
    "print(\"Normal Class F Measure : \",per_class_f_measure[0])\n",
    "print(\"AbNormal Class F Measure : \",per_class_f_measure[1])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 549
    },
    "id": "IpeF9mgyldMf",
    "outputId": "da2cda34-7052-4eb0-8324-61dfe3b7fba3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
