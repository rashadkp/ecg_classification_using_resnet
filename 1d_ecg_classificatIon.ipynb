{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "jyIMzGSA-_oZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.signal import butter, filtfilt\n",
    "import wfdb\n",
    "import pandas as pd\n",
    "import sys\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "A43FYGHX_iX-"
   },
   "outputs": [],
   "source": [
    "#definition of data path and excel file path\n",
    "path = '/home/abhishek/rashad_internship/Physionet/ptb-xl-1.0.3/'\n",
    "excel = '/home/abhishek/rashad_internship/Physionet/ptb-xl-1.0.3/ptbxl_database.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tozT3NrF_kAl"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from scipy.signal import butter, filtfilt\n",
    "import wfdb\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "class Custom_class(Dataset):\n",
    "    def __init__(self, path, num_data, transform=None, data_split='train', fold=10):\n",
    "        self.dat = pd.read_csv(path + 'ptbxl_database.csv',index_col='ecg_id')\n",
    "        self.statements = pd.read_csv(path + 'scp_statements.csv', index_col=0)\n",
    "        self.statements = self.statements[self.statements.diagnostic == 1]\n",
    "        self.dat.index = self.dat.index.astype(int)\n",
    "        self.dat.index = self.dat.reindex(range(0, 21799))\n",
    "        \n",
    "        # Add diagnostic superclass\n",
    "        self.dat.scp_codes = self.dat.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "        self.dat['diagnostic_superclass'] = self.dat.scp_codes.apply(self.aggregate_diagnostic)\n",
    "        self.dat = self.dat[self.dat['diagnostic_superclass'].apply(lambda x: len(x) > 0)]\n",
    "        \n",
    "        self.col = self.dat['filename_hr']  # only 500 hz files are used for training\n",
    "        self.label = self.dat['scp_codes']  # used for labeling\n",
    "        self.superclass_label = self.dat['diagnostic_superclass']  # diagnostic superclass label\n",
    "        self.strat_fold = self.dat['strat_fold']  # Load strat_fold column\n",
    "        self.path = path\n",
    "        self.transform = transform  # Initialize the transform attribute\n",
    "        self.num_data = num_data\n",
    "        self.data_split = data_split\n",
    "        self.fold = fold\n",
    "        \n",
    "        if self.data_split == 'train':\n",
    "            self.indices = [idx for idx in range(self.num_data) if (self.strat_fold[idx] <= self.fold)]\n",
    "        elif self.data_split == 'test':\n",
    "            self.indices = [idx for idx in range(self.num_data) if (self.strat_fold[idx] == self.fold)]\n",
    "        elif self.data_split == 'val':\n",
    "            self.indices = [idx for idx in range(self.num_data) if (self.strat_fold[idx] == self.fold)]\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = self.indices[idx]  # Adjust index to match filtered data\n",
    "        \n",
    "        y, _ = wfdb.rdsamp(self.path + self.col[idx])  # Use channel 0\n",
    "        y = y.astype(np.float32)\n",
    "        y = np.transpose(y)  # changing dimension from 5000, 12 to 12, 5000\n",
    "\n",
    "        # Apply filtering\n",
    "        y = self.bandpass_filter(y, 1, 47, 500)  # applying BPF\n",
    "\n",
    "        # Normalize using z-score\n",
    "        y = self.z_score_normalize(y)\n",
    "        y = y.astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "        # Get the diagnostic superclass label\n",
    "        superclass_list = self.superclass_label[idx]\n",
    "\n",
    "        # Determine label based on superclass list\n",
    "        if len(superclass_list) == 0 or len(superclass_list) > 1:\n",
    "            label = 1  # If superclass list is empty or contains more than one item, label as 1\n",
    "        else:\n",
    "            if superclass_list[0] == 'NORM':\n",
    "                label = 0  # If superclass contains only 'NORM', label as 0\n",
    "            else:\n",
    "                label = 1 \n",
    "\n",
    "        if self.transform:\n",
    "            y = self.transform(y)\n",
    "        \n",
    "\n",
    "        return y[0, :, :],  label\n",
    "\n",
    "    def bandpass_filter(self, data, lowcut, highcut, fs, order=3):\n",
    "        nyquist = 0.5 * fs\n",
    "        low = lowcut / nyquist\n",
    "        high = highcut / nyquist\n",
    "        b, a = butter(order, [low, high], btype='band')\n",
    "        y = filtfilt(b, a, data, axis=1)\n",
    "        return y\n",
    "\n",
    "    def z_score_normalize(self, data):\n",
    "        mean = np.mean(data, axis=1, keepdims=True)\n",
    "        std = np.std(data, axis=1, keepdims=True)\n",
    "        normalized_data = (data - mean) / std\n",
    "        return normalized_data\n",
    "\n",
    "    def aggregate_diagnostic(self, y_dic):\n",
    "        tmp = []\n",
    "        for key in y_dic.keys():\n",
    "            if key in self.statements.index:\n",
    "                tmp.append(self.statements.loc[key].diagnostic_class)\n",
    "        return list(set(tmp))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = Custom_class(path, num_data=7000, transform=transform, data_split='train',fold=8)\n",
    "\n",
    "\n",
    "# For test data\n",
    "test_dataset = Custom_class(path, num_data=7000, transform=transform, data_split='test',fold=10)\n",
    "\n",
    "# For validation data\n",
    "val_dataset = Custom_class( path, num_data=7000, transform=transform, data_split='val',fold=9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data in Training set : 5368\n",
      "Number of data in Validation set :803\n",
      "Number of data in Test set : 829\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of data in Training set : {len(train_dataset)}\")\n",
    "print(f\"Number of data in Validation set :{len(val_dataset)}\")\n",
    "print(f\"Number of data in Test set : {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "XI7KUi3h_-iL"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "# Define the Shannon Entropy calculation function\n",
    "def shannon_entropy(x):\n",
    "    B, C, T = x.size()\n",
    "    entropies = torch.zeros(B, C).to(x.device)\n",
    "    epsilon = 1e-10\n",
    "    for b in range(B):\n",
    "        for c in range(C):\n",
    "            total_sum = x[b, c, :].sum()\n",
    "            if total_sum == 0:\n",
    "                continue  # Skip channels with zero sum to avoid division by zero\n",
    "            p = x[b, c, :] / total_sum\n",
    "            p = p.clamp(min=epsilon)  # Clamp probabilities to avoid log(0)\n",
    "            entropies[b, c] = -torch.sum(p * torch.log2(p))\n",
    "    return entropies\n",
    "\n",
    "# Define the Res_Block_1\n",
    "class ResBlock1(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResBlock1, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=2, stride=2, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv3 = nn.Conv1d(out_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm1d(out_channels)\n",
    "        self.adjust_channels = nn.Conv1d(in_channels, out_channels, kernel_size=2, stride=2, padding=1)\n",
    "        self.adjust_bn = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.adjust_channels(x)\n",
    "        shortcut = self.adjust_bn(shortcut)\n",
    "\n",
    "        x = F.leaky_relu(self.bn1(self.conv1(x)))\n",
    "        x = F.leaky_relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = x + shortcut\n",
    "        x = F.leaky_relu(x)\n",
    "        return x\n",
    "\n",
    "# Define the Res_Block_2\n",
    "class ResBlock2(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResBlock2, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv3 = nn.Conv1d(out_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm1d(out_channels)\n",
    "        self.adjust_channels = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.adjust_bn = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.adjust_channels(x)\n",
    "        shortcut = self.adjust_bn(shortcut)\n",
    "\n",
    "        x = F.leaky_relu(self.bn1(self.conv1(x)))\n",
    "        x = F.leaky_relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = x + shortcut\n",
    "        x = F.leaky_relu(x)\n",
    "        return x\n",
    "\n",
    "# Define the complete ResNet-50 model with Self-Attention\n",
    "class ResNet50(nn.Module):\n",
    "    def __init__(self, input_channels=12, num_classes=2):\n",
    "        super(ResNet50, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(ResBlock1, 64, 128, 1)\n",
    "        self.layer2 = self._make_layer(ResBlock2, 128, 128, 2)\n",
    "        self.layer3 = self._make_layer(ResBlock1, 128, 256, 1)\n",
    "        self.layer4 = self._make_layer(ResBlock2, 256, 256, 3)\n",
    "        self.layer5 = self._make_layer(ResBlock1, 256, 512, 1)\n",
    "        self.layer6 = self._make_layer(ResBlock2, 512, 512, 5)\n",
    "        self.layer7 = self._make_layer(ResBlock1, 512, 1024, 1)\n",
    "        self.layer8 = self._make_layer(ResBlock2, 1024, 1024, 2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.dropout = nn.Dropout(p=0.5)  # added to improve generalization\n",
    "        self.fc1 = nn.Linear(1024, 512)  # 1024 (features) + 12 (entropies)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "\n",
    "    def _make_layer(self, block, in_channels, out_channels, blocks):\n",
    "        layers = []\n",
    "        layers.append(block(in_channels, out_channels))\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # entropy = shannon_entropy(x)  # Compute the entropy\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "        x = self.layer7(x)\n",
    "        x = self.layer8(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # x = torch.cat((x, entropy), dim=1)  # Concatenate the entropy to the features\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = torch.squeeze(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model and print the summary\n",
    "model = ResNet50(input_channels=12, num_classes=1)\n",
    "\n",
    "# Check if CUDA is available and move the model to the GPU if it is\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "_P3pWpWNGj7x"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True,num_workers=2)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True,num_workers=2)\n",
    "validation_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=True,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import math\n",
    "\n",
    "def lr_lambda(epoch):\n",
    "    if epoch < 10:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return math.exp(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rclVOfWEF8lt",
    "outputId": "cc132c7e-9ecb-4353-c11f-88ce1595e523"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/20: 100%|██████████| 168/168 [00:20<00:00,  8.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 1/20, Loss: 0.4858, Accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 1/20, Loss: 0.3665, Accuracy: 0.8456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/20: 100%|██████████| 168/168 [00:18<00:00,  9.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 2/20, Loss: 0.3753, Accuracy: 0.8355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 2/20, Loss: 0.3465, Accuracy: 0.8356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/20: 100%|██████████| 168/168 [00:19<00:00,  8.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 3/20, Loss: 0.3361, Accuracy: 0.8526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 3/20, Loss: 0.3307, Accuracy: 0.8543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/20: 100%|██████████| 168/168 [00:18<00:00,  8.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 4/20, Loss: 0.3181, Accuracy: 0.8618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 4/20, Loss: 0.3200, Accuracy: 0.8643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/20: 100%|██████████| 168/168 [00:18<00:00,  8.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 5/20, Loss: 0.2987, Accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 5/20, Loss: 0.3270, Accuracy: 0.8580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/20: 100%|██████████| 168/168 [00:18<00:00,  9.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 6/20, Loss: 0.2915, Accuracy: 0.8798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 6/20, Loss: 0.3335, Accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/20: 100%|██████████| 168/168 [00:18<00:00,  9.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 7/20, Loss: 0.2515, Accuracy: 0.8955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 7/20, Loss: 0.4020, Accuracy: 0.8493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/20: 100%|██████████| 168/168 [00:18<00:00,  9.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 8/20, Loss: 0.2500, Accuracy: 0.8959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 8/20, Loss: 0.3899, Accuracy: 0.8481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/20: 100%|██████████| 168/168 [00:18<00:00,  9.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 9/20, Loss: 0.2439, Accuracy: 0.8992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 9/20, Loss: 0.3569, Accuracy: 0.8568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/20: 100%|██████████| 168/168 [00:18<00:00,  9.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 10/20, Loss: 0.2115, Accuracy: 0.9098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 10/20, Loss: 0.3699, Accuracy: 0.8605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/20: 100%|██████████| 168/168 [00:18<00:00,  8.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 11/20, Loss: 0.1510, Accuracy: 0.9408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 11/20, Loss: 0.4435, Accuracy: 0.8518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/20: 100%|██████████| 168/168 [00:18<00:00,  9.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 12/20, Loss: 0.0810, Accuracy: 0.9702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 12/20, Loss: 0.4538, Accuracy: 0.8580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13/20: 100%|██████████| 168/168 [00:18<00:00,  9.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 13/20, Loss: 0.0686, Accuracy: 0.9732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 13/20, Loss: 0.5744, Accuracy: 0.8369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14/20: 100%|██████████| 168/168 [00:18<00:00,  9.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 14/20, Loss: 0.0657, Accuracy: 0.9745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 14/20, Loss: 0.5353, Accuracy: 0.8506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15/20: 100%|██████████| 168/168 [00:18<00:00,  9.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 15/20, Loss: 0.0472, Accuracy: 0.9823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 15/20, Loss: 0.6166, Accuracy: 0.8518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16/20: 100%|██████████| 168/168 [00:18<00:00,  9.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 16/20, Loss: 0.0499, Accuracy: 0.9816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 16/20, Loss: 0.7149, Accuracy: 0.8605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17/20: 100%|██████████| 168/168 [00:18<00:00,  9.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 17/20, Loss: 0.0475, Accuracy: 0.9832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 17/20, Loss: 0.5904, Accuracy: 0.8518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18/20: 100%|██████████| 168/168 [00:20<00:00,  8.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 18/20, Loss: 0.0431, Accuracy: 0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 18/20, Loss: 0.7077, Accuracy: 0.8531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19/20: 100%|██████████| 168/168 [00:18<00:00,  9.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 19/20, Loss: 0.0443, Accuracy: 0.9853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 19/20, Loss: 0.7569, Accuracy: 0.8381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20/20: 100%|██████████| 168/168 [00:18<00:00,  9.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 20/20, Loss: 0.0251, Accuracy: 0.9912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Epoch 20/20, Loss: 0.7337, Accuracy: 0.8543\n",
      "Training complete. Best validation accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "# Assuming you have defined your model, train_dataloader, validation_dataloader, device, etc.\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001) \n",
    "# scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "\n",
    "num_epochs = 20\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_acc = 0.0\n",
    "\n",
    "# Define your validation function\n",
    "def validate_model(model, dataloader, criterion):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc=\"Validation\", leave=False):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.float()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.round(outputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for inputs, labels in tqdm(train_dataloader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\"):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels = labels.float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.round(outputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataloader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(train_dataloader.dataset)\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f'Training - Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
    "\n",
    "    # Validate the model\n",
    "    val_loss, val_acc = validate_model(model, validation_dataloader, criterion)\n",
    "    print(f'Validation - Epoch {epoch+1}/{num_epochs}, Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}')\n",
    "\n",
    "    # Deep copy the model if the current validation accuracy is the best so far\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        # Save the best model\n",
    "        torch.save(model.state_dict(), \"best_model_fold_8.pth\")\n",
    "\n",
    "# Load best model weights\n",
    "model.load_state_dict(best_model_wts)\n",
    "\n",
    "print(f\"Training complete. Best validation accuracy: {best_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def is_number(x):\n",
    "    try:\n",
    "        float(x)\n",
    "        return True\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "\n",
    "def is_nan(x):\n",
    "    if is_number(x):\n",
    "        return np.isnan(float(x))\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def compute_one_hot_encoding(data, num_classes):\n",
    "    num_instances = len(data)\n",
    "    one_hot_encoding = np.zeros((num_instances, num_classes), dtype=np.bool_)\n",
    "    for i, x in enumerate(data):\n",
    "        if is_number(x) and not is_nan(x):\n",
    "            one_hot_encoding[i, int(x)] = 1\n",
    "    return one_hot_encoding\n",
    "\n",
    "def compute_one_vs_rest_confusion_matrix(labels, outputs, num_classes):\n",
    "    assert np.shape(labels) == np.shape(outputs)\n",
    "\n",
    "    num_instances = len(labels)\n",
    "    A = np.zeros((num_classes, 2, 2))\n",
    "    for i in range(num_instances):\n",
    "        for j in range(num_classes):\n",
    "            if labels[i, j] == 1 and outputs[i, j] == 1: # TP\n",
    "                A[j, 0, 0] += 1\n",
    "            elif labels[i, j] == 0 and outputs[i, j] == 1: # FP\n",
    "                A[j, 0, 1] += 1\n",
    "            elif labels[i, j] == 1 and outputs[i, j] == 0: # FN\n",
    "                A[j, 1, 0] += 1\n",
    "            elif labels[i, j] == 0 and outputs[i, j] == 0: # TN\n",
    "                A[j, 1, 1] += 1\n",
    "\n",
    "    return A\n",
    "\n",
    "# Compute macro F-measure.\n",
    "def compute_f_measure(labels, outputs):\n",
    "    # Find the number of classes.\n",
    "    classes = sorted(set(labels) | set(outputs))\n",
    "    num_classes = len(classes)\n",
    "\n",
    "    # Convert labels and outputs to one-hot encoded format.\n",
    "    labels_one_hot = compute_one_hot_encoding(labels, num_classes)\n",
    "    outputs_one_hot = compute_one_hot_encoding(outputs, num_classes)\n",
    "\n",
    "    # Compute confusion matrix.\n",
    "    A = compute_one_vs_rest_confusion_matrix(labels_one_hot, outputs_one_hot, num_classes)\n",
    "\n",
    "    per_class_f_measure = np.zeros(num_classes)\n",
    "    for k in range(num_classes):\n",
    "        tp, fp, fn, tn = A[k, 0, 0], A[k, 0, 1], A[k, 1, 0], A[k, 1, 1]\n",
    "        if 2 * tp + fp + fn > 0:\n",
    "            per_class_f_measure[k] = float(2 * tp) / float(2 * tp + fp + fn)\n",
    "        else:\n",
    "            per_class_f_measure[k] = float('nan')\n",
    "\n",
    "    if np.any(np.isfinite(per_class_f_measure)):\n",
    "        macro_f_measure = np.nanmean(per_class_f_measure)\n",
    "    else:\n",
    "        macro_f_measure = float('nan')\n",
    "\n",
    "    return macro_f_measure, per_class_f_measure, classes\n",
    "\n",
    "# Example usage\n",
    "# labels = [0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1]\n",
    "# outputs = [0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1]\n",
    "\n",
    "# macro_f_measure, per_class_f_measure, classes = compute_f_measure(labels, outputs)\n",
    "# print(\"Macro F-Measure:\", macro_f_measure)\n",
    "# print(\"Per Class F-Measure:\", per_class_f_measure)\n",
    "# print(\"Classes:\", classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P08h1mCVhVPI",
    "outputId": "977f2580-2673-4d9d-b400-24e941f2b885"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:83.95657418576599 %\n",
      "AUC Score: 0.9069940476190476\n",
      "F1 Score: 0.8440797186400938\n",
      "Precision: 0.8888888888888888\n",
      "Specificity: 0.8818897637795275\n",
      "F Measure :  0.839431163667873\n",
      "Normal Class F Measure :  0.8347826086956521\n",
      "AbNormal Class F Measure :  0.8440797186400938\n",
      "Confusion Matrix:\n",
      "[[336  45]\n",
      " [ 88 360]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, f1_score, precision_score\n",
    "\n",
    "model = ResNet50(input_channels=12, num_classes=1)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load('/home/abhishek/rashad_internship/ecg_classification_using_resnet/best_model_fold_8.pth'))\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_preds_1 = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, labels in test_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            outputs = model(data)\n",
    "            all_preds_1.extend(outputs.cpu().numpy())\n",
    "            preds = torch.round(outputs)\n",
    "            preds = preds.int()\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    # Calculate AUC\n",
    "    auc = roc_auc_score(all_labels, all_preds_1)\n",
    "\n",
    "    # Calculate F1 Score\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "    # Calculate Precision\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "\n",
    "    # Calculate Specificity\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    macro_f_measure, per_class_f_measure, classes = compute_f_measure(all_labels,all_preds)\n",
    "\n",
    "    return accuracy, cm, auc, f1, precision, specificity,macro_f_measure, per_class_f_measure, classes\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `model` is your PyTorch model and `test_loader` is your test data loader\n",
    "accuracy, cm, auc, f1, precision, specificity,macro_f_measure, per_class_f_measure, classes = test_model(model, test_dataloader)\n",
    "print(f\"Accuracy:{ accuracy*100} %\")\n",
    "print(\"AUC Score:\", auc)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"F Measure : \",macro_f_measure)\n",
    "print(\"Normal Class F Measure : \",per_class_f_measure[0])\n",
    "print(\"AbNormal Class F Measure : \",per_class_f_measure[1])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 549
    },
    "id": "IpeF9mgyldMf",
    "outputId": "da2cda34-7052-4eb0-8324-61dfe3b7fba3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
