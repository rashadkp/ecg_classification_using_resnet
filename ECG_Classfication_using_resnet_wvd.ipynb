{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17d8a72d-74f8-4659-afb8-884de151e814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import wfdb\n",
    "import pandas as pd\n",
    "import wignerdpy\n",
    "from wignerdpy.toolkits import signal_toolkit\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2a7c4d8-d6fd-4a69-b4e7-8d0f37e9e1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel = \"/home/abhishek/rashad_internship/Physionet/ptb-xl-1.0.3/ptbxl_database.csv\"\n",
    "path = '/home/abhishek/rashad_internship/Physionet/ptb-xl-1.0.3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0453a7eb-fb9c-471f-8cd2-6b1f08930d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import wfdb\n",
    "import wignerdpy\n",
    "from wignerdpy.toolkits import signal_toolkit\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "import ast\n",
    "import random\n",
    "\n",
    "class SingleToThreeChannel:\n",
    "    def __call__(self, image):\n",
    "        return image.repeat(3, 1, 1)\n",
    "    \n",
    "class onedimTotwodim:\n",
    "    def __call__(self, data):\n",
    "        k, _ = wignerdpy.wigner_distribution(data, sample_frequency=500)\n",
    "        resized_matrix = zoom(k, (224/5000, 224/5000))\n",
    "        return resized_matrix.astype(np.float32)\n",
    "\n",
    "# Correcting the transforms.Compose\n",
    "transform = transforms.Compose([\n",
    "    onedimTotwodim(),  # Apply WVD transformation\n",
    "    transforms.ToTensor(), # Convert single-channel to three-channel\n",
    "])\n",
    "\n",
    "class Custom_class(Dataset):\n",
    "    def __init__(self, excelfile, path, num_data, transform=None, data_split='train', fold=None):\n",
    "        self.dat = pd.read_csv(excelfile)\n",
    "        self.col = self.dat['filename_hr']\n",
    "        self.label = self.dat['scp_codes']\n",
    "        self.strat_fold = self.dat['strat_fold']\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        self.num_data = num_data\n",
    "        self.data_split = data_split\n",
    "        self.fold = fold\n",
    "        \n",
    "\n",
    "        if self.data_split == 'train':\n",
    "            self.indices = [idx for idx in range(self.num_data) if (self.strat_fold[idx] != fold)]\n",
    "        elif self.data_split == 'test':\n",
    "            self.indices = [idx for idx in range(self.num_data) if (self.strat_fold[idx] == fold)]\n",
    "        elif self.data_split == 'val':\n",
    "            self.indices = [idx for idx in range(self.num_data) if (self.strat_fold[idx] == fold)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Randomly select a channel between 0 and 11\n",
    "        channel = random.randint(0, 11)\n",
    "        idx = self.indices[idx]\n",
    "        \n",
    "        # Read the signal for the randomly selected channel\n",
    "        y, _ = wfdb.rdsamp(self.path + self.col[idx], channels=[channel])\n",
    "        y = y.flatten()  # Ensure y is a 1D array\n",
    "        \n",
    "        scp_code_dict = ast.literal_eval(self.label[idx])\n",
    "        first_key = max(scp_code_dict, key=scp_code_dict.get)  # one key in scp_code dictionary with highest value is considered as label\n",
    "        label = 0 if first_key == 'NORM' else 1\n",
    "        \n",
    "        if self.transform:\n",
    "            y = self.transform(y)\n",
    "            \n",
    "        return y, label\n",
    "\n",
    "# Example usage\n",
    "train_dataset = Custom_class(excel,path, 1000, transform,data_split='train',fold = 10)\n",
    "validation_dataset = Custom_class(excel,path, 1000, transform,data_split='test',fold = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d58f03d-3652-40f6-a7f7-c55a9e6815b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create DataLoaders for train and test sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(validation_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7c5ab19-c9dd-4227-bbd4-77bc2ebac6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet50\n",
    "from torch.nn import MultiheadAttention\n",
    "\n",
    "class CustomResNet50(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(CustomResNet50, self).__init__()\n",
    "        # Load pre-trained ResNet-50\n",
    "        self.resnet = resnet50(pretrained=True)\n",
    "\n",
    "        # Modify the first convolutional layer to accept single-channel input\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "        # Extract layers up to the penultimate layer\n",
    "        self.features = nn.Sequential(*list(self.resnet.children())[:-2])\n",
    "\n",
    "        # Define Multi-Head Attention parameters\n",
    "        self.attention = MultiheadAttention(embed_dim=2048, num_heads=1, batch_first=True)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(2048, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract features\n",
    "        x = self.features(x)\n",
    "\n",
    "        # Global average pooling\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1)).view(x.size(0), -1)\n",
    "\n",
    "        # Add dimension for attention (batch_size, seq_len, embed_dim)\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        # Apply multi-head attention\n",
    "        attn_output, _ = self.attention(x, x, x)\n",
    "\n",
    "        # Remove the extra dimension\n",
    "        attn_output = attn_output.squeeze(1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(attn_output))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        x = torch.sigmoid(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "model = CustomResNet50(num_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4425c958-dc56-4f6a-9462-30f82095c36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00778f03-7bc0-4a1c-9040-5ba5350d17cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [22:12<00:00, 47.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 1/25, Loss: 0.7016, Accuracy: 0.4971\n",
      "Validation - Epoch 1/25, Loss: 0.6930, Accuracy: 0.4961\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [22:11<00:00, 47.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 2/25, Loss: 0.6926, Accuracy: 0.5132\n",
      "Validation - Epoch 2/25, Loss: 0.6990, Accuracy: 0.4884\n",
      "Epoch 3/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [22:21<00:00, 47.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 3/25, Loss: 0.6913, Accuracy: 0.5419\n",
      "Validation - Epoch 3/25, Loss: 0.6980, Accuracy: 0.5039\n",
      "Epoch 4/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [22:15<00:00, 47.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 4/25, Loss: 0.6923, Accuracy: 0.5258\n",
      "Validation - Epoch 4/25, Loss: 0.6897, Accuracy: 0.5039\n",
      "Epoch 5/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [22:12<00:00, 47.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 5/25, Loss: 0.6901, Accuracy: 0.5454\n",
      "Validation - Epoch 5/25, Loss: 0.6888, Accuracy: 0.5504\n",
      "Epoch 6/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [22:24<00:00, 48.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 6/25, Loss: 0.7092, Accuracy: 0.5281\n",
      "Validation - Epoch 6/25, Loss: 0.6938, Accuracy: 0.4884\n",
      "Epoch 7/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [22:30<00:00, 48.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 7/25, Loss: 0.6921, Accuracy: 0.5270\n",
      "Validation - Epoch 7/25, Loss: 0.6961, Accuracy: 0.4884\n",
      "Epoch 8/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [22:34<00:00, 48.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 8/25, Loss: 0.6913, Accuracy: 0.5258\n",
      "Validation - Epoch 8/25, Loss: 0.6947, Accuracy: 0.4884\n",
      "Epoch 9/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [22:35<00:00, 48.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 9/25, Loss: 0.6908, Accuracy: 0.5270\n",
      "Validation - Epoch 9/25, Loss: 0.6912, Accuracy: 0.5271\n",
      "Epoch 10/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [22:42<00:00, 48.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 10/25, Loss: 0.6884, Accuracy: 0.5431\n",
      "Validation - Epoch 10/25, Loss: 0.6893, Accuracy: 0.5271\n",
      "Epoch 11/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [22:43<00:00, 48.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 11/25, Loss: 0.6878, Accuracy: 0.5568\n",
      "Validation - Epoch 11/25, Loss: 0.6939, Accuracy: 0.5504\n",
      "Epoch 12/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [22:30<00:00, 48.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 12/25, Loss: 0.6878, Accuracy: 0.5557\n",
      "Validation - Epoch 12/25, Loss: 0.6887, Accuracy: 0.5426\n",
      "Epoch 13/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [22:34<00:00, 48.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 13/25, Loss: 0.6853, Accuracy: 0.5637\n",
      "Validation - Epoch 13/25, Loss: 0.6895, Accuracy: 0.5736\n",
      "Epoch 14/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [22:25<00:00, 48.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 14/25, Loss: 0.6842, Accuracy: 0.5786\n",
      "Validation - Epoch 14/25, Loss: 0.6846, Accuracy: 0.5814\n",
      "Epoch 15/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [22:25<00:00, 48.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 15/25, Loss: 0.6841, Accuracy: 0.5511\n",
      "Validation - Epoch 15/25, Loss: 0.6781, Accuracy: 0.6124\n",
      "Epoch 16/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [22:24<00:00, 48.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 16/25, Loss: 0.6850, Accuracy: 0.5557\n",
      "Validation - Epoch 16/25, Loss: 0.6848, Accuracy: 0.5814\n",
      "Epoch 17/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [22:16<00:00, 47.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 17/25, Loss: 0.6850, Accuracy: 0.5637\n",
      "Validation - Epoch 17/25, Loss: 0.6911, Accuracy: 0.5349\n",
      "Epoch 18/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [22:26<00:00, 48.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 18/25, Loss: 0.6853, Accuracy: 0.5511\n",
      "Validation - Epoch 18/25, Loss: 0.6818, Accuracy: 0.5736\n",
      "Epoch 19/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [22:24<00:00, 48.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 19/25, Loss: 0.6863, Accuracy: 0.5545\n",
      "Validation - Epoch 19/25, Loss: 0.7004, Accuracy: 0.5271\n",
      "Epoch 20/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [22:26<00:00, 48.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 20/25, Loss: 0.6857, Accuracy: 0.5672\n",
      "Validation - Epoch 20/25, Loss: 0.6879, Accuracy: 0.5736\n",
      "Epoch 21/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [22:26<00:00, 48.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 21/25, Loss: 0.6817, Accuracy: 0.5649\n",
      "Validation - Epoch 21/25, Loss: 0.6937, Accuracy: 0.5349\n",
      "Epoch 22/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [22:16<00:00, 47.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 22/25, Loss: 0.6783, Accuracy: 0.5924\n",
      "Validation - Epoch 22/25, Loss: 0.6866, Accuracy: 0.5659\n",
      "Epoch 23/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [22:13<00:00, 47.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 23/25, Loss: 0.6802, Accuracy: 0.5913\n",
      "Validation - Epoch 23/25, Loss: 0.6925, Accuracy: 0.5271\n",
      "Epoch 24/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [22:14<00:00, 47.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 24/25, Loss: 0.6809, Accuracy: 0.5993\n",
      "Validation - Epoch 24/25, Loss: 0.6944, Accuracy: 0.5194\n",
      "Epoch 25/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [22:15<00:00, 47.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 25/25, Loss: 0.6820, Accuracy: 0.5798\n",
      "Validation - Epoch 25/25, Loss: 0.6893, Accuracy: 0.5659\n",
      "Training complete. Best validation accuracy: 0.6124\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "# scheduler = LambdaLR(optimizer, lr_lambda)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "num_epochs = 25\n",
    "# best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_acc = 0.0\n",
    "\n",
    "def validate_model(model, dataloader, criterion):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.float()\n",
    "\n",
    "            outputs = model(inputs).squeeze(1)\n",
    "            preds = torch.round(outputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    \n",
    "    # Wrap the train_loader with tqdm\n",
    "    for inputs, labels in tqdm(train_loader, desc='Training'):\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        labels = labels.to(device)\n",
    "        labels = labels.float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs).squeeze(1)\n",
    "        preds = torch.round(outputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f'Training - Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
    "\n",
    "    # Validate the model\n",
    "    val_loss, val_acc = validate_model(model, val_loader, criterion)\n",
    "    print(f'Validation - Epoch {epoch+1}/{num_epochs}, Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}')\n",
    "\n",
    "    # Deep copy the model if the current validation accuracy is the best so far\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        # Save the best model\n",
    "        torch.save(model.state_dict(), \"best_model_resnet.pth\")\n",
    "\n",
    "# Load best model weights\n",
    "model.load_state_dict(best_model_wts)\n",
    "\n",
    "print(f\"Training complete. Best validation accuracy: {best_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a462ec4-ef78-4c9d-bc63-080d488aff03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
