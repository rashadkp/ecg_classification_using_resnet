{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17d8a72d-74f8-4659-afb8-884de151e814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import wfdb\n",
    "import pandas as pd\n",
    "import wignerdpy\n",
    "from wignerdpy.toolkits import signal_toolkit\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2a7c4d8-d6fd-4a69-b4e7-8d0f37e9e1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel = \"/home/abhishek/rashad_internship/Physionet/ptb-xl-1.0.3/ptbxl_database.csv\"\n",
    "path = '/home/abhishek/rashad_internship/Physionet/ptb-xl-1.0.3/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddf425e",
   "metadata": {},
   "source": [
    "R Peak detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0453a7eb-fb9c-471f-8cd2-6b1f08930d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import wfdb\n",
    "import wignerdpy\n",
    "from wignerdpy.toolkits import signal_toolkit\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "import ast\n",
    "import random\n",
    "from scipy.signal import ShortTimeFFT,get_window\n",
    "import cv2\n",
    "\n",
    "\n",
    "class SingleToThreeChannel:\n",
    "    def __call__(self, image):\n",
    "        return image.repeat(3, 1, 1)\n",
    "    \n",
    "class onedimTotwodim:\n",
    "    def __call__(self, data):\n",
    "        # Assuming this is your existing transformation\n",
    "        # This can be replaced with STFT transformation\n",
    "        stft_transformer = ShortTimeFFT(get_window('hann', 300), hop=100, fs=500)\n",
    "        Zxx = stft_transformer.stft(data)\n",
    "        spectrogram = np.abs(Zxx)  # Take absolute values of STFT\n",
    "        plt.figure(figsize=(6, 6))  # Adjust figure size as needed\n",
    "        plt.pcolormesh(spectrogram, shading='gouraud')\n",
    "        plt.axis('off')  # Remove axes for a cleaner image\n",
    "        plt.savefig('temp_spectrogram.png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()\n",
    "\n",
    "        # Load the saved image\n",
    "        image = cv2.imread('temp_spectrogram.png')\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "\n",
    "        # Resize the image to 224x224\n",
    "        resized_image = cv2.resize(image, (224, 224))\n",
    "\n",
    "        # Convert to tensor\n",
    "        resized_image_tensor = transforms.ToTensor()(resized_image)\n",
    "\n",
    "        return resized_image_tensor\n",
    "# Correcting the transforms.Compose\n",
    "transform = transforms.Compose([\n",
    "    onedimTotwodim(),  # Apply WVD transformation\n",
    "    # transforms.ToTensor(), # Convert single-channel to three-channel\n",
    "])\n",
    "\n",
    "class Custom_class(Dataset):\n",
    "    def __init__(self, excelfile, path, num_data, transform=None, data_split='train', fold=None):\n",
    "        self.dat = pd.read_csv(excelfile)\n",
    "        self.col = self.dat['filename_hr']\n",
    "        self.label = self.dat['scp_codes']\n",
    "        self.strat_fold = self.dat['strat_fold']\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        self.num_data = num_data\n",
    "        self.data_split = data_split\n",
    "        self.fold = fold\n",
    "        \n",
    "\n",
    "        if self.data_split == 'train':\n",
    "            self.indices = [idx for idx in range(self.num_data) if (self.strat_fold[idx] != fold)]\n",
    "        elif self.data_split == 'test':\n",
    "            self.indices = [idx for idx in range(self.num_data) if (self.strat_fold[idx] == fold)]\n",
    "        elif self.data_split == 'val':\n",
    "            self.indices = [idx for idx in range(self.num_data) if (self.strat_fold[idx] == fold)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Randomly select a channel between 0 and 11\n",
    "        channel = random.randint(0, 11)\n",
    "        idx = self.indices[idx]\n",
    "        \n",
    "        # Read the signal for the randomly selected channel\n",
    "        y, _ = wfdb.rdsamp(self.path + self.col[idx], channels=[channel])\n",
    "        y = y.flatten()  # Ensure y is a 1D array\n",
    "        y = y[:1500]\n",
    "        \n",
    "        scp_code_dict = ast.literal_eval(self.label[idx])\n",
    "        first_key = max(scp_code_dict, key=scp_code_dict.get)  # one key in scp_code dictionary with highest value is considered as label\n",
    "        label = 0 if first_key == 'NORM' else 1\n",
    "        \n",
    "        if self.transform:\n",
    "            y = self.transform(y)\n",
    "        \n",
    "            \n",
    "        return y, label\n",
    "\n",
    "# Example usage\n",
    "train_dataset = Custom_class(excel,path, 1000, transform,data_split='train',fold = 10)\n",
    "validation_dataset = Custom_class(excel,path, 1000, transform,data_split='test',fold = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7f0c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,label = train_dataset[0]\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d58f03d-3652-40f6-a7f7-c55a9e6815b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create DataLoaders for train and test sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(validation_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7c5ab19-c9dd-4227-bbd4-77bc2ebac6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet50\n",
    "from torch.nn import MultiheadAttention\n",
    "\n",
    "class CustomResNet50(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(CustomResNet50, self).__init__()\n",
    "        # Load pre-trained ResNet-50\n",
    "        self.resnet = resnet50(pretrained=True)\n",
    "\n",
    "        # Modify the first convolutional layer to accept single-channel input\n",
    "        self.resnet.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "        # Extract layers up to the penultimate layer\n",
    "        self.features = nn.Sequential(*list(self.resnet.children())[:-2])\n",
    "\n",
    "        # Define Multi-Head Attention parameters\n",
    "        self.attention = MultiheadAttention(embed_dim=2048, num_heads=1, batch_first=True)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(2048, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract features\n",
    "        x = self.features(x)\n",
    "\n",
    "        # Global average pooling\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1)).view(x.size(0), -1)\n",
    "\n",
    "        # Add dimension for attention (batch_size, seq_len, embed_dim)\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        # Apply multi-head attention\n",
    "        attn_output, _ = self.attention(x, x, x)\n",
    "\n",
    "        # Remove the extra dimension\n",
    "        attn_output = attn_output.squeeze(1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(attn_output))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        x = torch.sigmoid(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "model = CustomResNet50(num_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4425c958-dc56-4f6a-9462-30f82095c36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00778f03-7bc0-4a1c-9040-5ba5350d17cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [01:45<00:00,  3.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 1/25, Loss: 0.6709, Accuracy: 0.5890\n",
      "Validation - Epoch 1/25, Loss: 0.6939, Accuracy: 0.5349\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [01:31<00:00,  3.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 2/25, Loss: 0.6981, Accuracy: 0.4902\n",
      "Validation - Epoch 2/25, Loss: 0.7026, Accuracy: 0.4884\n",
      "Epoch 3/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [01:32<00:00,  3.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 3/25, Loss: 0.6932, Accuracy: 0.5258\n",
      "Validation - Epoch 3/25, Loss: 0.6942, Accuracy: 0.4884\n",
      "Epoch 4/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [01:31<00:00,  3.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 4/25, Loss: 0.6923, Accuracy: 0.5258\n",
      "Validation - Epoch 4/25, Loss: 0.6958, Accuracy: 0.4884\n",
      "Epoch 5/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [01:32<00:00,  3.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 5/25, Loss: 0.6939, Accuracy: 0.5040\n",
      "Validation - Epoch 5/25, Loss: 0.6931, Accuracy: 0.5116\n",
      "Epoch 6/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [01:34<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 6/25, Loss: 0.6932, Accuracy: 0.5166\n",
      "Validation - Epoch 6/25, Loss: 0.6940, Accuracy: 0.4884\n",
      "Epoch 7/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [01:35<00:00,  3.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 7/25, Loss: 0.6923, Accuracy: 0.5258\n",
      "Validation - Epoch 7/25, Loss: 0.6946, Accuracy: 0.4884\n",
      "Epoch 8/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [01:32<00:00,  3.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 8/25, Loss: 0.6913, Accuracy: 0.5258\n",
      "Validation - Epoch 8/25, Loss: 0.6949, Accuracy: 0.4884\n",
      "Epoch 9/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [01:34<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 9/25, Loss: 0.6911, Accuracy: 0.5258\n",
      "Validation - Epoch 9/25, Loss: 0.6942, Accuracy: 0.4884\n",
      "Epoch 10/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [01:30<00:00,  3.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 10/25, Loss: 0.6905, Accuracy: 0.5258\n",
      "Validation - Epoch 10/25, Loss: 0.6937, Accuracy: 0.4884\n",
      "Epoch 11/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [01:35<00:00,  3.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 11/25, Loss: 0.6892, Accuracy: 0.5258\n",
      "Validation - Epoch 11/25, Loss: 0.6925, Accuracy: 0.4884\n",
      "Epoch 12/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [01:31<00:00,  3.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 12/25, Loss: 0.6873, Accuracy: 0.5258\n",
      "Validation - Epoch 12/25, Loss: 0.6946, Accuracy: 0.4884\n",
      "Epoch 13/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [01:30<00:00,  3.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 13/25, Loss: 0.6752, Accuracy: 0.5258\n",
      "Validation - Epoch 13/25, Loss: 0.6997, Accuracy: 0.4884\n",
      "Epoch 14/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [01:30<00:00,  3.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 14/25, Loss: 0.6667, Accuracy: 0.6119\n",
      "Validation - Epoch 14/25, Loss: 0.6602, Accuracy: 0.6202\n",
      "Epoch 15/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [01:30<00:00,  3.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 15/25, Loss: 0.6446, Accuracy: 0.6659\n",
      "Validation - Epoch 15/25, Loss: 0.6715, Accuracy: 0.6124\n",
      "Epoch 16/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [01:30<00:00,  3.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 16/25, Loss: 0.6336, Accuracy: 0.6935\n",
      "Validation - Epoch 16/25, Loss: 0.6601, Accuracy: 0.6279\n",
      "Epoch 17/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [01:37<00:00,  3.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 17/25, Loss: 0.6376, Accuracy: 0.6487\n",
      "Validation - Epoch 17/25, Loss: 0.6624, Accuracy: 0.6124\n",
      "Epoch 18/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [01:34<00:00,  3.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 18/25, Loss: 0.6339, Accuracy: 0.6590\n",
      "Validation - Epoch 18/25, Loss: 0.6443, Accuracy: 0.6434\n",
      "Epoch 19/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [01:41<00:00,  3.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 19/25, Loss: 0.6194, Accuracy: 0.6728\n",
      "Validation - Epoch 19/25, Loss: 0.6452, Accuracy: 0.6357\n",
      "Epoch 20/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [01:33<00:00,  3.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 20/25, Loss: 0.6155, Accuracy: 0.6567\n",
      "Validation - Epoch 20/25, Loss: 0.7005, Accuracy: 0.5504\n",
      "Epoch 21/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [01:40<00:00,  3.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 21/25, Loss: 0.6067, Accuracy: 0.6762\n",
      "Validation - Epoch 21/25, Loss: 0.6358, Accuracy: 0.6279\n",
      "Epoch 22/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [01:32<00:00,  3.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 22/25, Loss: 0.5902, Accuracy: 0.6946\n",
      "Validation - Epoch 22/25, Loss: 0.6466, Accuracy: 0.6202\n",
      "Epoch 23/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [01:36<00:00,  3.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 23/25, Loss: 0.5988, Accuracy: 0.6889\n",
      "Validation - Epoch 23/25, Loss: 0.5881, Accuracy: 0.7287\n",
      "Epoch 24/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [01:41<00:00,  3.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 24/25, Loss: 0.6016, Accuracy: 0.6797\n",
      "Validation - Epoch 24/25, Loss: 0.6229, Accuracy: 0.6589\n",
      "Epoch 25/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 28/28 [01:47<00:00,  3.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Epoch 25/25, Loss: 0.6113, Accuracy: 0.6762\n",
      "Validation - Epoch 25/25, Loss: 0.6241, Accuracy: 0.6512\n",
      "Training complete. Best validation accuracy: 0.7287\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "# scheduler = LambdaLR(optimizer, lr_lambda)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "num_epochs = 25\n",
    "# best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_acc = 0.0\n",
    "\n",
    "def validate_model(model, dataloader, criterion):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.float()\n",
    "\n",
    "            outputs = model(inputs).squeeze(1)\n",
    "            preds = torch.round(outputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    \n",
    "    # Wrap the train_loader with tqdm\n",
    "    for inputs, labels in tqdm(train_loader, desc='Training'):\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        labels = labels.to(device)\n",
    "        labels = labels.float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs).squeeze(1)\n",
    "        preds = torch.round(outputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f'Training - Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
    "\n",
    "    # Validate the model\n",
    "    val_loss, val_acc = validate_model(model, val_loader, criterion)\n",
    "    print(f'Validation - Epoch {epoch+1}/{num_epochs}, Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}')\n",
    "\n",
    "    # Deep copy the model if the current validation accuracy is the best so far\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        # Save the best model\n",
    "        torch.save(model.state_dict(), \"best_model_resnet.pth\")\n",
    "\n",
    "# Load best model weights\n",
    "model.load_state_dict(best_model_wts)\n",
    "\n",
    "print(f\"Training complete. Best validation accuracy: {best_acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
