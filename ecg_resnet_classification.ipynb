{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rashadkp/ecg_classification_using_resnet/blob/master/ecg_resnet_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bu1tum-WbJM7"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ljbkusters/python-wigner-distribution.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d1Zl0NdbMGZ",
        "outputId": "d8949217-077d-4290-c349-e68063520a74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/python-wigner-distribution\n"
          ]
        }
      ],
      "source": [
        "cd python-wigner-distribution"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8MBOR3erPJT",
        "outputId": "b964cbb3-4fff-4e7a-e656-e32c23173301"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxeY7yE4bX6T"
      },
      "outputs": [],
      "source": [
        "pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "iWqdxheWPApb"
      },
      "outputs": [],
      "source": [
        "!pip install wfdb\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from scipy import signal\n",
        "import wfdb\n",
        "import pandas as pd\n",
        "# import wignerdpy\n",
        "# from wignerdpy.toolkits import signal_toolkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "bv4mZNTMZ9Nd"
      },
      "outputs": [],
      "source": [
        "Y = pd.read_csv('/content/drive/MyDrive/Physionet/ptb-xl/ptbxl_database.csv', index_col='ecg_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "xkXEHiNGZ-AX"
      },
      "outputs": [],
      "source": [
        "Y = Y[:987]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "l8QwvyEiasoh"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/Physionet/ptb-xl/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import torch\n",
        "import torch.fft\n",
        "import numpy as np\n",
        "from scipy import signal"
      ],
      "metadata": {
        "id": "5xtgAco7Fx63"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_raw_data(df, path):\n",
        "    data = []\n",
        "    for i, filename in enumerate(df.filename_hr):\n",
        "        record, meta = wfdb.rdsamp(path + filename, channels=[1])\n",
        "        data.append(record)\n",
        "        # Print and overwrite the previous message\n",
        "        sys.stdout.write(f\"\\rRecord {filename} is read successfully.\")\n",
        "        sys.stdout.flush()\n",
        "    # Print a new line at the end to move the cursor to the next line\n",
        "    print()\n",
        "\n",
        "    # Convert the list to a PyTorch tensor\n",
        "    data = np.array(data)\n",
        "\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "1Fu8-4NJHp1V"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGYdNb1Uac3C",
        "outputId": "3f6af1c3-218c-4ef9-9490-9da0d6800070"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Record records500/00000/00512_hr is read successfully.\n"
          ]
        }
      ],
      "source": [
        "X = load_raw_data(Y,path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "dABN5enOd1Pw"
      },
      "outputs": [],
      "source": [
        "def check_norm(d):\n",
        "    if isinstance(d, str):\n",
        "        d = eval(d)  # Convert string representation of dictionary to dictionary\n",
        "        first_key = list(d.keys())[0]\n",
        "        if first_key == 'NORM':\n",
        "            return 0\n",
        "        else:\n",
        "            return 1\n",
        "    else:\n",
        "        return np.nan\n",
        "\n",
        "# Apply the function to the 'scp_codes' column\n",
        "Y['norm_indicator'] = Y['scp_codes'].apply(check_norm)\n",
        "\n",
        "# Convert the 'norm_indicator' column to a numpy array\n",
        "labels = Y['norm_indicator'].values\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Z=Z[:,:,0]"
      ],
      "metadata": {
        "id": "bg5d-9v2539K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSoFx4UucbW9"
      },
      "outputs": [],
      "source": [
        "sample_data = X[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X[:,:,0]\n"
      ],
      "metadata": {
        "id": "XW2EbwKtUq51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.ndimage import zoom\n",
        "import os"
      ],
      "metadata": {
        "id": "kpEo8NKUctSQ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.ndimage import zoom"
      ],
      "metadata": {
        "id": "wRZYmgsJVFSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojczqozpl2tD"
      },
      "source": [
        "Wigner Ville Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNkIQjsucXwA"
      },
      "outputs": [],
      "source": [
        "wigner_dist, max_freq = wignerdpy.wigner_distribution(sample_data, sample_frequency = 500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQIPKzpml7J3"
      },
      "outputs": [],
      "source": [
        "def twodimrep(signal):\n",
        "  ret=[]\n",
        "  for i in range(len(signal)):\n",
        "    k,_ = wignerdpy.wigner_distribution(signal[i], sample_frequency = 500)\n",
        "    resized_matrix = zoom(k, (224/5000, 224/5000))\n",
        "    sys.stdout.write(f\"\\rRecord {i} is converted to matrix successfully.\")\n",
        "    sys.stdout.flush()\n",
        "    ret.append(resized_matrix)\n",
        "  return ret"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A =X[:10]"
      ],
      "metadata": {
        "id": "fgk3NAObbvTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tw5gtFermRz_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b28e236-9573-43f9-f3c0-44986b541384"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Record 499 is converted to matrix successfully."
          ]
        }
      ],
      "source": [
        "im = twodimrep(X)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SAM = twodimrep(Z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGVbl9hv6Jqf",
        "outputId": "5ba0e772-5de3-409a-c118-9b294ae8ac3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Record 99 is converted to matrix successfully."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pS8fvXdPYUz"
      },
      "source": [
        "RESNET"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wvd_data = np.load(\"/content/drive/MyDrive/ECG_TRAINING_CHECKPOINT/wvd_of_ecg.npy\")"
      ],
      "metadata": {
        "id": "AXI-cNtGdgjy"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = wvd_data[:700]\n",
        "train_label = labels[:700]\n",
        "test_data = wvd_data[700:987]\n",
        "test_label = labels[700:987]"
      ],
      "metadata": {
        "id": "Q00f98Rbhodm"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchvision numpy wandb"
      ],
      "metadata": {
        "id": "ckhYjP7zAxV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, labels, transform=None):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Assuming `data_list` is your list of 224x224 matrices and `labels` is the numpy array of size 987x1\n",
        "# data_list = ...  # Your data here\n",
        "# labels = ...     # Your labels here\n",
        "\n",
        "# Convert to numpy arrays\n",
        "data_array = np.stack(train_data)\n",
        "labels_array = train_label.flatten()\n",
        "\n",
        "class SingleToThreeChannel:\n",
        "    def __call__(self, image):\n",
        "        return image.repeat(3, 1, 1)\n",
        "# Transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.ToTensor(),\n",
        "    SingleToThreeChannel(),\n",
        "])\n",
        "\n",
        "# Create dataset and dataloader\n",
        "dataset = CustomDataset(data_array, labels_array, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
      ],
      "metadata": {
        "id": "K3BOqQ9sA3K1"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "wandb.init(project=\"resnet50-classification\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "6Q4xVzByDKgm",
        "outputId": "5b0c3ae8-0aae-47c1-907a-cb3fd4dc7918"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240522_090213-4lt5ck6d</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/rashadkp99/resnet50-classification/runs/4lt5ck6d' target=\"_blank\">expert-voice-3</a></strong> to <a href='https://wandb.ai/rashadkp99/resnet50-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/rashadkp99/resnet50-classification' target=\"_blank\">https://wandb.ai/rashadkp99/resnet50-classification</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/rashadkp99/resnet50-classification/runs/4lt5ck6d' target=\"_blank\">https://wandb.ai/rashadkp99/resnet50-classification/runs/4lt5ck6d</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/rashadkp99/resnet50-classification/runs/4lt5ck6d?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7b7a584e8970>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "# Load pretrained ResNet50\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Modify the final fully connected layer\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)  # Assuming 2 classes\n",
        "\n",
        "# Move the model to the GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "Mb8F3ryTDWzC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "636797fd-5d69-4de8-8a3c-ac8575cab75f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import copy\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "num_epochs = 25\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "best_acc = 0.0\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    epoch_loss = running_loss / len(dataset)\n",
        "    epoch_acc = running_corrects.double() / len(dataset)\n",
        "\n",
        "    wandb.log({\"loss\": epoch_loss, \"accuracy\": epoch_acc})\n",
        "\n",
        "    print(f'Epoch {epoch}/{num_epochs - 1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
        "\n",
        "    # Deep copy the model if the current accuracy is the best so far\n",
        "    if epoch_acc > best_acc:\n",
        "        best_acc = epoch_acc\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "# Load best model weights\n",
        "model.load_state_dict(best_model_wts)\n",
        "\n",
        "# Save the best model\n",
        "torch.save(model.state_dict(), \"best_model.pth\")\n",
        "\n",
        "print(f\"Training complete. Best accuracy: {best_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "J-x-UhEdDcEL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5be2ec45-f27b-41d5-bada-6d3e318b9f09"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24, Loss: 0.7201, Accuracy: 0.4886\n",
            "Epoch 1/24, Loss: 0.6506, Accuracy: 0.6043\n",
            "Epoch 2/24, Loss: 0.5379, Accuracy: 0.7443\n",
            "Epoch 3/24, Loss: 0.3382, Accuracy: 0.9029\n",
            "Epoch 4/24, Loss: 0.1398, Accuracy: 0.9857\n",
            "Epoch 5/24, Loss: 0.0472, Accuracy: 1.0000\n",
            "Epoch 6/24, Loss: 0.0256, Accuracy: 0.9986\n",
            "Epoch 7/24, Loss: 0.0141, Accuracy: 1.0000\n",
            "Epoch 8/24, Loss: 0.0154, Accuracy: 1.0000\n",
            "Epoch 9/24, Loss: 0.0133, Accuracy: 1.0000\n",
            "Epoch 10/24, Loss: 0.0156, Accuracy: 1.0000\n",
            "Epoch 11/24, Loss: 0.0105, Accuracy: 1.0000\n",
            "Epoch 12/24, Loss: 0.0127, Accuracy: 1.0000\n",
            "Epoch 13/24, Loss: 0.0138, Accuracy: 1.0000\n",
            "Epoch 14/24, Loss: 0.0143, Accuracy: 1.0000\n",
            "Epoch 15/24, Loss: 0.0118, Accuracy: 1.0000\n",
            "Epoch 16/24, Loss: 0.0119, Accuracy: 1.0000\n",
            "Epoch 17/24, Loss: 0.0117, Accuracy: 1.0000\n",
            "Epoch 18/24, Loss: 0.0112, Accuracy: 1.0000\n",
            "Epoch 19/24, Loss: 0.0114, Accuracy: 1.0000\n",
            "Epoch 20/24, Loss: 0.0088, Accuracy: 1.0000\n",
            "Epoch 21/24, Loss: 0.0103, Accuracy: 1.0000\n",
            "Epoch 22/24, Loss: 0.0130, Accuracy: 1.0000\n",
            "Epoch 23/24, Loss: 0.0115, Accuracy: 1.0000\n",
            "Epoch 24/24, Loss: 0.0117, Accuracy: 0.9986\n",
            "Training complete. Best accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing"
      ],
      "metadata": {
        "id": "LdWRiL2j4Ijn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "# Load the model architecture\n",
        "model = models.resnet50()\n",
        "\n",
        "# Modify the final fully connected layer\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)  # Assuming 2 classes\n",
        "\n",
        "# Load the best model weights\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/ECG_TRAINING_CHECKPOINT/best_model.pth\"))\n",
        "\n",
        "# Move the model to the GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "\n",
        "# Custom transform to convert single channel to 3 channels\n",
        "class SingleToThreeChannel:\n",
        "    def __call__(self, image):\n",
        "        return image.repeat(3, 1, 1)\n",
        "\n",
        "# Define the transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.ToTensor(),\n",
        "    SingleToThreeChannel(),  # Convert single channel to 3 channels\n",
        "])\n",
        "\n",
        "# Example single input (replace this with your actual input)\n",
        "single_input = wvd_data[986]  # Dummy single-channel input\n",
        "\n",
        "# Apply the transformations\n",
        "input_tensor = transform(single_input)\n",
        "\n",
        "# Add batch dimension\n",
        "input_tensor = input_tensor.unsqueeze(0)\n",
        "\n",
        "# Move the input tensor to the GPU if available\n",
        "input_tensor = input_tensor.to(device)\n"
      ],
      "metadata": {
        "id": "_pitoJAU0RBb"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels)"
      ],
      "metadata": {
        "id": "_HfcTRP2nLCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run inference\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_tensor)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "# Convert the predicted class index to a class label (0 or 1)\n",
        "predicted_class = predicted.item()\n",
        "\n",
        "print(f\"Predicted class: {predicted_class}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdDeAbpD4RRo",
        "outputId": "2d559a93-fac8-4afe-af67-5b2460ee561b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test data"
      ],
      "metadata": {
        "id": "1zwiZJw1f_YY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Load the model architecture\n",
        "model = models.resnet50()\n",
        "\n",
        "# Modify the final fully connected layer\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)  # Assuming 2 classes\n",
        "\n",
        "# Load the best model weights\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/ECG_TRAINING_CHECKPOINT/best_model.pth\"))\n",
        "\n",
        "# Move the model to the GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Assuming you have your test data and labels as test_data and test_labels respectively\n",
        "\n",
        "# List to store predicted labels\n",
        "all_predicted = []\n",
        "# List to store ground truth labels\n",
        "all_labels = []\n",
        "\n",
        "\n",
        "\n",
        "# Iterate over test data\n",
        "for single_input in test_data:\n",
        "    # Apply transformations\n",
        "    input_tensor = transform(single_input)\n",
        "    input_tensor = input_tensor.unsqueeze(0)\n",
        "    input_tensor = input_tensor.to(device)\n",
        "\n",
        "    # Run inference\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_tensor)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    # Append predicted and ground truth labels\n",
        "    all_predicted.append(predicted.item())\n",
        "    # Assuming test_labels is a list of ground truth labels\n",
        "    all_labels.append(test_label[len(all_predicted)-1])  # assuming same length\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "all_predicted = np.array(all_predicted)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "# Create confusion matrix\n",
        "conf_matrix = confusion_matrix(all_labels, all_predicted)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhV8OYWqgAx0",
        "outputId": "67d7d8fb-22f9-4a9f-ba55-250f38fb4616"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[100  46]\n",
            " [ 57  84]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "zy7zRsVvg2U1",
        "outputId": "eef8cbe7-fb97-44fd-9e1d-3b6d02f2ad35"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy\n",
        "accuracy = np.trace(conf_matrix) / np.sum(conf_matrix)\n",
        "\n",
        "# Calculate precision\n",
        "precision = np.diag(conf_matrix) / np.sum(conf_matrix, axis=0)\n",
        "\n",
        "print(f'Accuracy: {accuracy*100:.2f}')\n",
        "print(f'Precision for class 0: {precision[0]:.2f}')\n",
        "print(f'Precision for class 1: {precision[1]:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQMtSpEWg-sq",
        "outputId": "ad7dad49-a702-4472-db1a-40af609e0599"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 64.11\n",
            "Precision for class 0: 0.64\n",
            "Precision for class 1: 0.65\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}